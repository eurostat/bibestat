<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<file xmlns="http://bibtexml.sf.net/">
    <entry id="BGV19">
        <article>
            <author>Bikauskaite, A. and G{\"o}tzfried, A. and V{\"o}lfinger, Z.</author>
            <title>The {E}uro{G}roups {R}egister</title>
            <journal>#J_Statistika#</journal>
            <year>2019</year>
            <volume>99</volume>
            <number>1</number>
            <pages>69-76</pages>
            <abstract>Globalisation presents significant statistical challenges, particularly for small and open economies in terms of measuring statistical indicators and communicating the results to users. The European Statistical System allocated high priority to the better measuring of globalisation in the statistical processes and output, in business or macro-economic statistics. Some concrete actions were already undertaken such as setting up of the EuroGroups Register of multinational enterprise groups and the putting in place of a so-called Early-warning System for monitoring restructurings of the groups. This paper focuses on the EuroGroups Register (EGR), the central statistical business register of Eurostat and the EU and EFTA countries' statistical authorities. The EGR is part of the EU statistical infrastructure and has been built up to better capture globalisation effects as well as for improving the consistency of national data on enterprise groups 4 .</abstract>
            <url>https://www.czso.cz/documents/10180/88506450/32019719q1_069.pdf</url>
        </article>
    </entry>
    <entry id="Bujnowska19">
        <incollection>
            <author>Bujnowska, A.</author>
            <title>Access to {E}uropean {S}tatistical {S}ystem microdata</title>
            <booktitle>Data-Driven Policy Impact Evaluation \textendash{} How Access to Microdata is Transforming Policy Design</booktitle>
            <publisher>#P_S#</publisher>
            <year>2019</year>
            <editor>Crato, N. and Paruolo, P.</editor>
            <pages>87-99</pages>
            <doi>10.1007/978-3-319-78461-8</doi>
            <url>https://www.springer.com/gp/book/9783319784601</url>
        </incollection>
    </entry>
    <entry id="GGM19">
        <inproceedings>
            <author>Grazzini, J. and Gaffuri, J. and Museux, J.-M.</author>
            <title>Delivering {O}fficial {S}tatistics as {D}o-{I}t-{Y}ourself services to foster produsers' engagement with {E}urostat open data</title>
            <booktitle>#C_NTTS#</booktitle>
            <year>2019</year>
            <abstract>Opening up data obviously provides the opportunity to involve actors from outside the European Statistical System - say produsers, e.g., statisticians, scientists, citizens - and promote innovative, user-centric ways to tackle new and existing policy issues by co-designing statistical products. This also has the potential to increase National Statistical Offices efficiency and effectiveness. However, open data alone does not automatically translate to public participation to the decision-making. In most data provision services, there is an overarching top-down ideology since statistical processes are still owned, dictated and designed by National Statistical Offices and the final users are only involved as the receivers of the data and/or services . We propose to move away from the current approach by providing tools and software for accessing and using online data, so as to enable sharing best practices, learning from others' experience, adopt common methodologies, enhance cooperation between data producers and data users, and further engage in Open Data-driven innovation.</abstract>
            <doi>10.5281/zenodo.3240272</doi>
            <url>https://www.researchgate.net/publication/332079417_Delivering_Official_Statistics_as_Do-It-Yourself_services_to_foster_produsers'_engagement_with_Eurostat_open_data</url>
        </inproceedings>
    </entry>
    <entry id="Lamboray19">
        <inproceedings>
            <author>Lamboray, C.</author>
            <title>Elementary aggregation: {A} not so elementary story!</title>
            <booktitle>#M_MOG#</booktitle>
            <year>2019</year>
            <abstract>The compilation of a CPI is often presented in two stages. First, prices are aggregated without weights at the elementary level. Prices are typically obtained from dedicated surveys for which price collectors visit outlets  and  record  the  observed  prices.  These  elementary  price  indices  are  then  aggregated  to  the  higher  levels using expenditure weights.  Nowadays,  CPIs  are  becoming  a  multi-source  statistics  where  prices  are  obtained  not  only  from  price  collection  in  the  field  but  also  from  transaction  data,  administrative  data  or  from  the  Internet  using  web  scraping techniques. Depending on the data source, different strategies can be adopted for constructing the elementary aggregates and for compiling elementary price indices. A CPI may be compiled in more than two stages and weights may be available even within the elementary aggregates. With scanner data, the index compiler must make two main structural decisions which can have a significant impact on inflation measurement. First, the item which is being aggregated must be defined. Second, the level must be fixed up to which these items are first aggregated. To discuss this second issue, we distinguish two strategies for a category that can be divided into sub-categories. Either the items are directly aggregated to the category level, possibly using a multilateral method. Alternatively, the multilateral method aggregates only up to the sub-category level, and these intermediate sub-category level indices are then aggregated to the  category  level  using  for  instance  a  Laspeyres-type  index  formula.  The  objective  of  this  paper  is  to  examine the impact of introducing this additional level of fixity in the CPI structure.</abstract>
            <url>https://eventos.fgv.br/sites/eventos.fgv.br/files/arquivos/u161/elementary_aggregation_og_lamboray.pdf</url>
        </inproceedings>
    </entry>
    <entry id="LGRMGMH19">
        <inproceedings>
            <author>Luhmann, S. and Grazzini, J. and Ricciato, F. and Meszaros, M. and Giannakouris, K. and Museux, J.-M. and Hahn, M.</author>
            <title>Promoting reproducibility-by-design in statistical offices</title>
            <booktitle>#C_NTTS#</booktitle>
            <year>2019</year>
            <abstract>This paper emphasizes the need for Official Statistics to go beyond current practice and exceed the limits of the National Statistical Offices and the European Statistical System to reach and engage with produsers - e.g. statisticians, scientists and citizens. Through the adoption of some best practices derived from the Open Source Software community and the integration of modern technological solutions, the "Shared, Transparent, Auditable, Trusted, Participative, Reproducible, and Open" principles can help create new participatory models of knowledge and information production.</abstract>
            <doi>10.5281/zenodo.3240198</doi>
            <url>https://www.researchgate.net/publication/332045930_Promoting_reproducibility-by-design_in_statistical_offices</url>
        </inproceedings>
    </entry>
    <entry id="Meszaros19">
        <inproceedings>
            <author>M\'esz\'aros, M.</author>
            <title>Aggregating flags \textendash{} {A} standardised and rational approach</title>
            <booktitle>#C_NTTS#</booktitle>
            <year>2019</year>
            <note>\href{https://coms.events/ntts2019/data/full_papers/full_paper_90.pdf}{Online poster}</note>
            <abstract>A flag is an attribute of a cell in a data set that provides additional qualitative information about the statistical value of that cell. They can indicate a wide range of information, for example, that a given value is estimated, confidential or represents a break in the time series. Currently different sets of flags are in use in the European Statistical System (ESS). Some statistical domains use the SDMX code list for observation status and confidentiality status, OECD uses a simplified version of the SDMX code lists and Eurostat uses a short list of flags for dissemination which combines the observation and confidentiality status. While in most cases it is well defined how a flag shall be assigned to an individual value, it is not straightforward to decide what flag shall be propagated to aggregated values like a sum, an average, quantiles, etc. This topic is important for Eurostat as the European aggregates are derived from national data points. Thus the information contained in the individual flags need to be summarized in a flag for the aggregate. This issue is not unique to Eurostat, but can occur for any aggregated data. For example, a national statistical institute may derive the national aggregate from regional data sets. In addition, the dissemination process provides further peculiarity: only a limited set of flags, compared to the set of flags used in the production process, can be applied in order to make it easily understandable to the users. In the scientific community there is a wide range of research about the consequences of data aggregation but it concentrates only on the information loss during aggregation of information and there is no scientific guidance how to aggregate flags. This paper is an attempt to provide a picture about the current situation and provide some systematic guidance how to aggregate flags in a coherent way. Eurostat is testing various approaches with a view to well balance transparency and clarity of the information made available to users in a flag. From several options, 3 methods (hierarchical, frequency and weighted frequency) are implemented in an R package for assigning a flag to an aggregate based on the underlying flags and values. Since the topic has relevance outside of Eurostat as well, it was decided to publish the respective code with documentation with a view to foster re-use within the European Statistical System and to stimulate discussion, including with the user community.</abstract>
            <url>https://coms.events/ntts2019/data/x_abstracts/x_abstract_90.docx</url>
        </inproceedings>
    </entry>
    <entry id="RWGRS19">
        <article>
            <author>Ricciato, F. and Wirthmann, A. and Giannakouris, K. and Reis, F. and Skaliotis, M.</author>
            <title>Trusted smart statistics: {M}otivations and principles</title>
            <journal>#J_SJIAOS#</journal>
            <year>2019</year>
            <volume>35</volume>
            <number>4</number>
            <pages>589-603</pages>
            <abstract>In this contribution we outline the concept of Trusted Smart Statistics as the natural evolution of official statistics in the new datafied world. Traditional data sources, namely survey and administrative data, represent nowadays a valuable but small portion of the global data stock, much thereof being held in the private sector. The availability of new data sources is only one aspect of the global change that concerns official statistics. Other aspects, more subtle but not less important, include the changes in perceptions, expectations, behaviours and relations between the stakeholders. The environment around official statistics has changed: statistical offices are not any more data monopolists, but one prominent species among many others in a larger (and complex) ecosystem. What was established in the traditional world of legacy data sources (in terms of regulations, technologies, practices, etc.) is not guaranteed to be sufficient any more with new data sources. Trusted Smart Statistics is not about replacing existing sources and processes, but augmenting them with new ones. Such augmentation however will not be only incremental: the path towards Trusted Smart Statistics is not about tweaking some components of the legacy system but about building an entirely new system that will coexist with the legacy one. In this position paper we outline some key design principles for the new Trusted Smart Statistics system. Taken collectively they picture a system where the smart and trust aspects enable and reinforce each other. A system that is more extrovert towards external stakeholders (citizens, private companies, public authorities) with whom Statistical Offices will be sharing computation, control, code, logs and of course final statistics, without necessarily sharing the raw input data. </abstract>
            <doi>10.3233/SJI-190584</doi>
            <url>https://content.iospress.com/articles/statistical-journal-of-the-iaos/sji190584</url>
        </article>
    </entry>
    <entry id="RBWHB19">
        <inproceedings>
            <author>Ricciato, F. and Bujnowska, A. and Wirthmann, A. and Hahn, M. and Barredo-Capelot, E.</author>
            <title>A reflection on privacy and data confidentiality in {O}fficial {S}tatistics</title>
            <booktitle>#C_ISI_WSC#</booktitle>
            <year>2019</year>
            <abstract>The  availability of new digital data sources represents an opportunity for Statistical  Offices (SO) to complement traditional statistics and/or deliver novel statistics with improved timeliness and relevance. Nowadays SOs are  part of a larger "data ecosystem" where different organizations, including public institutions and private companies, engage in  the collection and processing of different kinds of (new) data about citizens, companies, goods etc.  In this multi-actors scenario it is often desirable to let one organization extract some output statistics (i.e., aggregate information) from input data that are held by other organization(s) in different administrative domain(s). We refer to this problem as cross-domain statistical processing. To achieve this goal, the most intuitive approach - but not the only one - is  to exchange raw input data across administrative domains (organizations). However, this  strategy is not always viable when personal input data are involved, due to a combination of regulatory constraints (including lack of explicit legal basis for data sharing), business confidentiality, privacy  requirements, or a combination of the above. Furthermore, new data sources often embed a much more pervasive view about individuals than traditional survey and/or administrative data, an aspect that amplifies the potential risks of data concentration. In such cases, performing cross-domain  statistical processing requires technologies to elicit only the agreed-upon output information (exactly or approximately) without revealing the input data. This entails addressing two  distinct but complementary problems. First, we need to compute the desired output statistics without seeing the raw input data. Second, we need to control the amount of information that might be inferred about individual data subjects in the input dataset from the output. In the field of privacy engineering the notions of "input privacy" and "output privacy" are used to refer respectively to these two problems. We remark that these problems are separable, i.e., they can be addressed with distinct tools and methods that get combined together, overlaid or juxtaposed. In this contribution we review recent advances in  both fields and briefly discuss their complementary roles. As for input privacy, we provide a brief introduction to the fundamental principles of Secure Multi-Party Computation (SMPC). As for output privacy, we review recent advances in the field of Statistical Disclosure Control (SDC). Finally, we discuss possible scenarios for SMPC and SDC integration in the future "confidentiality engineering" setup of modern official statistics.</abstract>
            <url>https://www.bis.org/ifc/events/isi_wsc_62/ips177_paper3.pdf</url>
        </inproceedings>
    </entry>
    <entry id="RB19">
        <inproceedings>
            <author>Ricciato, F. and Bujnowska, A.</author>
            <title>Privacy and data confidentiality for {O}fficial {S}tatistics: {N}ew challenges and new tools</title>
            <booktitle>#C_NTTS#</booktitle>
            <year>2019</year>
            <month>#mar#</month>
            <abstract>The modern society is undergoing a process of massive datafication. The availability of new digital data sources represents an opportunity for Statistical Offices (SO) to complement traditional statistics as well as to produce novel statistical products with improved timeliness and relevance. However, such opportunities come with important challenges in almost every aspect – methodological, business models, data governance,regulation, organizational and others. The new scenario calls for an evolution of the modus operandi adopted by SO also with respect to privacy and data confidentiality, that is the focus of the present contribution. We propose here a discussion framework focused on the prospective combination of advanced Statistical Disclosure Control (SDC) methods with Secure Multi-Party Computation (SMC) techniques.</abstract>
            <url>https://coms.events/ntts2019/data/x_abstracts/x_abstract_190.pdf</url>
        </inproceedings>
    </entry>
    <entry id="RLW19">
        <inproceedings>
            <author>Ricciato, F. and Lanzieri, G. and Wirthmann, A.</author>
            <title>Towards a methodological framework for estimating present population density from {M}obile {N}etwork {O}perator data</title>
            <booktitle>#W_ADSS#</booktitle>
            <year>2019</year>
            <abstract>The concept of 'present population' is gaining increasing attention in official statistics. The (almost) continuous measurement of present population provides a basis to derive indicators of population exposure that are relevant in different application domains. One possible approach to measure  present population exploits data  from  Mobile Network Operators (MNO), including CDR but also more  informative (and  complex) signalling records. Such data, collected primarily for network operation processes, can be repurposed to infer patterns of human mobility. Two decades of research literature have produced several case studies (mostly limited to CDR data) and a variety of ad-hoc methodologies tailored to specific datasets. Moving  beyond  the stage of explorative research, towards production of official  statistics, requires a more systematic and sustainable approach to methodological development. Towards this aim, Eurostat and other members of the European Statistical System (ESS are working towards the definition of a general Reference Methodological Framework.  In this contribution we report on the methodological aspects related to the estimation of present population density, for which we present a general and modular methodological structure. Along the way, we identify a number of specific  research (sub)problems requiring further attention by the research community.</abstract>
            <url>https://ec.europa.eu/eurostat/cros/system/files/mno_spatial_density_ricciato_lanzieri_wirthmann_2019_v1.pdf</url>
        </inproceedings>
    </entry>
    <entry id="RW19">
        <inproceedings>
            <author>Ricciato, F. and Wirthmann, A.</author>
            <title>Trusted {S}mart {S}tatistics: {H}ow new data will change {O}fficial {S}tatistics</title>
            <booktitle>#C_DfP#</booktitle>
            <year>2019</year>
            <abstract>In this discussion paper we outline the motivations and the main principles of the Trusted Smart Statistics concept under development in the European Statistical System (ESS) to respond to the challenges posed by the prospective use of innovative digital data sources for the production of official statistics.</abstract>
            <doi>10.5281/zenodo.3066060</doi>
            <url>https://zenodo.org/record/3066061/files/ricciato_wirthmann_Data4Policy_2019.pdf</url>
        </inproceedings>
    </entry>
    <entry id="RWH19">
        <inproceedings>
            <author>Ricciato, F. and Wirthmann, A. and Hahn, M.</author>
            <title>Integrating alternative data sources into {O}fficial {S}tatistics: {A} system-design approach</title>
            <booktitle>#C_ECE_CES#</booktitle>
            <year>2019</year>
            <month>#jun#</month>
            <organization>#O_UNECE#</organization>
            <abstract>New types of digital data sources (or "big data") are now available as by-product of other technological processes. New data  sources differ from the traditional data sources in use  for official  statistics, namely survey data and administrative records,  along  multiple dimensions. Therefore, the adoption of new data sources for the regular production of official statistics requires innovations  at  multiple  levels,  including  new  processing  paradigms, computation methods, data access and governance models, staff skills, etc. The term "Trusted Smart  Statistics" was  put  forward by Eurostat to indicate  a  comprehensive  framework to evolve official statistics towards adoption of new data sources along with traditional ones. In this document we  focus  on  the  need to take  a  systemic  view,  and  in  general  a system-design  approach,  towards  the  development of novel  processing  methodologies  for new types of data. We argue for the need to identify selected 'classes' of new data types (e.g., mobile network operator data, smart energy meters, satellite images, etc.) and, for each class, to  build a general  Reference Methodological Framework as basis for  developing  specific methodologies for particular use-cases and statistical products. We discuss the principles that should inform the construction of such framework, and briefly report on the ongoing work being conducted at Eurostat for one particular class of data, namely mobile network operator data.</abstract>
            <url>http://www.unece.org/fileadmin/DAM/stats/documents/ece/ces/2019/ECE_CES_2019_32_Eurostat.pdf</url>
        </inproceedings>
    </entry>
    <entry id="RV19">
        <inproceedings>
            <author>R\'emond-Tiedrez, I. and Valderas Jaramillo, J. M.</author>
            <title>The {E}urostat's balanced view of trade in services</title>
            <booktitle>#C_IIOC#</booktitle>
            <year>2019</year>
            <abstract>Asymmetries due to the mismatching in  the data  provided by one country and the mirror flow provided by its partner country for the  same  transactions are an  important issue in trade statistics, especially when it comes to link all European Union (EU) economies as in the FIGARO dataset. Although at EU level, balance of payments statisticians and trade in services statisticians follow up regularly on the asymmetries and try to reduce  them, we needed to implement a methodology for compiling a balanced view of trade in services as an input to the EU inter-country supply, use and input-output tables.For  the  first  release of FIGARO tables for the year 2010, the 2010  international  trade in services data (ITSS) serves as the  primary input.  Their exports and imports (or mirror exports)  are subsequently cleaned, imputed, estimated, modelled and confronted with Balance of Payments data to get a full dataset for 29 countries (EU Member States plus USA), 30 partner countries (plus RoW) and a number of services items.  The balancing of the resulting exports and import  values to solve the bilateral trade asymmetries is based on the methodology   developed   by   the   European Commission and  the OECD. As the EU inter-country supply, use and input-output tables present economies using the activity and product classification, the last step is to bridge the balanced trade view of the data from services categories to product classification (CPA/CPC). The paper  summarises the steps as compiled for the 2010 tables and shows the way foreseen to improve the compilation steps for the time series  2010-2016.  We also evaluate the impact on the original input data of each of the steps involved.</abstract>
            <url>https://www.iioa.org/conferences/27th/papers/files/3736.pdf</url>
        </inproceedings>
    </entry>
    <entry id="RRB19">
        <article>
            <author>Rueda-Cantuche, J. M. and Amores, A. F. and R\'emond-Tiedrez, I.</author>
            <title>Can supply, use and input–output tables be converted to a different classification with aggregate information?</title>
            <journal>#J_ESR#</journal>
            <year>2019</year>
            <abstract>Every change in the product and/or industry classifications and/or methodology of supply, use and input-output tables makes any medium- to long-term policy analysis impossible unless appropriate conversions are provided by national statistical institutes using more detailed data. However, can these tables be reasonably converted to a different classification of industries and products using aggregate information? We develop a conversion method that allows changes in classification that are independent of the number of industries and products. In addition, we provide evidence about its empirical performance compared with projection methods. We find projection methods perform better than conversion methods, at least when using aggregate information. Nonetheless, unlike conversion methods, projection methods generally require supply, use and input/output tables in the new classification that might not always be available. In their absence, we recommend using more detailed and sophisticated data.</abstract>
            <doi>10.1080/09535314.2019.1655393</doi>
            <url>https://www.tandfonline.com/doi/full/10.1080/09535314.2019.1655393</url>
        </article>
    </entry>
    <entry id="RVR19">
        <inproceedings>
            <author>Rueda-Cantuche, J. M. and Velazquez-Afonso, A. and R\'emond-Tiedrez, I.</author>
            <title>Traceability of the assumptions made in the construction of the {EU} inter-country supply, use and input-output tables</title>
            <booktitle>#C_IIOC#</booktitle>
            <year>2019</year>
            <note>\href{https://www.iioa.org/conferences/27th/papers/files/3855.pdf}{Online abstract}</note>
            <abstract>The modular approach adopted  in the construction of the EU inter-country supply, use and input-output tables (Figaro  project) to map the different adjustments and imputations made to the original data allows each adjustment/imputation to be measured at the different stages of the compilation process. As a result, this paper provides summary statistics based on: the comparison between the international merchandise and services trade  data adjusted for goods sent abroad for processing and merchanting activities and the trade values in the  national available SUTs (i.e. discrepancies); the analysis of the row and column total discrepancies by countries, users and products; the analysis of the final balancing adjustments made to  estimate  the  inter-country use table without discrepancies, by countries, users and products.This analysis provides useful information for the user of the FIGARO tables and helps producers in: highlighting the importance of the scope of some of the statistics they produce; identifying what type of  data is still missing from national statistical offices; and identifying where to put more efforts in future revisions. All these aspects are relevant for the compilation process.</abstract>
            <url>https://www.iioa.org/conferences/27th/papers/files/3855_20190423101_FIGARO_book_chapter13.pdf</url>
        </inproceedings>
    </entry>
    <entry id="SLM19">
        <article>
            <author>Sanz, A. F. and Luhmann, S. and Moraleda, A. G.</author>
            <title>Official {S}tatistics through the eyes of students and teachers \textendash{} {T}he {E}uropean {S}tatistics {C}ompetition</title>
            <journal>#J_AWSA#</journal>
            <year>2019</year>
            <volume>13</volume>
            <pages>245-255</pages>
            <doi>10.1007/s11943-019-00249-5</doi>
            <url>https://link.springer.com/content/pdf/10.1007\%2Fs11943-019-00249-5.pdf</url>
        </article>
    </entry>
    <entry id="SWFL19">
        <inproceedings>
            <author>Selenius, J. and Wirtz, C. and Florescu, D. and Lazar, A. C.</author>
            <title>Agricultural census 2020 \textendash{} {H}ow to reduce costs and burden? {T}he {E}uropean {S}tatistical {S}ystem approach</title>
            <booktitle>#C_ISI_WSC#</booktitle>
            <year>2019</year>
        </inproceedings>
    </entry>
    <entry id="SSEO19">
        <article>
            <author>Sutcliffe, L. M. E. and Schraml, A. and Eiselt, B. and Oppermann, R.</author>
            <title>The {LUCAS} grassland module pilot \textendash{} {Q}ualitative monitoring of grassland in {E}urope</title>
            <journal>#J_PG#</journal>
            <year>2019</year>
            <volume>40</volume>
            <pages>27-31</pages>
            <abstract>The Land Use/Cover Area-Frame  Survey (LUCAS) is a European inventory carried out every three years and coordinated by Eurostat. It aims to provide information for policy and science on land use, land cover and environmental parameters by surveying a statistically representative sample of points spread across the EU countries. In 2018, a new grassland module was piloted within the survey. This pilot aims to collect detailed information on the environmental and ecological quality of the grassland, as well as its type and intensity of use.  Between  April  and  July  2018,  3734  grassland  points  in  26  countries  were  surveyed  using  this standardised  methodology.  Of these points,  747  underwent  an  additional  quality  control  to  check  the  accuracy  of  the  survey  method.  This  is  the  first  time  a  standardised methodology  has  been  used  to  collect  ecological  data  on  grasslands  in  a  coordinated  manner  over  so  wide  a  geographical  range in Europe.  The  analysis  of  the  data from  this survey  is  ongoing,  so  the  purpose  of  this  article  is  to  briefly  describe  the  method  used  in  the new grassland module and inform readers about how this pilot was developed.</abstract>
            <doi>10.21570/EDGG.PG40</doi>
            <url>https://edgg.org/sites/default/files/page/Palaearctic_Grasslands_40_0.pdf</url>
        </article>
    </entry>
    <entry id="WSL19">
        <inproceedings>
            <author>Wirtz, C. and Selenius, J. and Lazar, A. C.</author>
            <title>Modernisation of the {E}uropean {A}gricultural {S}tatistics {S}ystem ({EASS}): {S}trategy for agricultural statistics 2020 and beyond</title>
            <booktitle>#C_ISI_WSC#</booktitle>
            <year>2019</year>
        </inproceedings>
    </entry>
    <entry id="Bach18">
        <incollection>
            <author>Bach, F.</author>
            <title>Statistical disclosure control in geospatial data: {T}he 2021 {EU} {C}ensus example</title>
            <booktitle>Service-Oriented Mapping \textendash{} Changing Paradigm in Map Production and Geoinformation Management</booktitle>
            <publisher>#P_S#</publisher>
            <year>2018</year>
            <editor>D\"ollner, J. and Jobst, M. and Schmitz, P.</editor>
            <series>#S_LNGC#</series>
            <pages>365-384</pages>
            <abstract>This chapter outlines challenges and modern approaches in statistical disclosure control of official high-resolution population data on the example of the EU census rounds 2011 and 2021, where a particular focus is on the European 1 km grid outputs derived from these censuses. After a general introduction to the topic and experiences from 2011, the recommended protection methods for geospatial data in the planned 2021 census 1 km grids are discussed in detail.</abstract>
            <doi>10.1007/978-3-319-72434-8_18</doi>
            <url>https://link.springer.com/content/pdf/10.1007\%2F978-3-319-72434-8.pdf</url>
        </incollection>
    </entry>
    <entry id="BKB18">
        <inproceedings>
            <author>Bach, F. and Kloek, W. and Bujnowska, A.</author>
            <title>Statistical confidentiality: {N}ew initiatives in the {E}uropean {S}tatistical {S}ystem</title>
            <booktitle>#C_Quality#</booktitle>
            <year>2018</year>
            <note>\href{https://www.q2018.pl/wp-content/uploads/Sessions/Session%2031/Fabian%20Bach/Session%2031_Fabian%20Bach.pptx}{Online presentation}</note>
            <abstract>The protection of confidential information has a huge impact on how statistical data can be published and used for analysis, which makes it a key aspect of data quality. This paper presents new methods and tools currently being investigated in the ESS in order to publish more - and more useful - data without compromising statistical confidentiality. It covers new methodological and IT developments, where concrete use cases demonstrate their impact on data quality. For instance, a promising methodological direction is random noise: several ESS use cases at different maturity stages are presented, including recommendations for the harmonised protection of 2021 EU Census data. Another direction is to reflect at a more fundamental level where protection is needed. Several ideas will be presented along this line.</abstract>
            <url>https://www.q2018.pl/wp-content/uploads/Sessions/Session%2031/Fabian%20Bach/Session%2031_%20Fabian%20Bach.docx</url>
        </inproceedings>
    </entry>
    <entry id="BEMBFGGHIMOPSTD18">
        <manual>
            <author>Buono, D. and Elliott, D. and Mazzi, G. L. and Bikker, R. and Fr{\"o}lich, M. and Gatto, R. and Guardalbascio, B. and Hauf, S. and Infante, E. and Moauro, F. and Oltmanns, E. and Palate, J. and Safr, K. and Tibert Stoltze, P. and Di Iorio, F.</author>
            <title>{ESS} guidelines on temporal disaggregation, benchmarking and reconciliation</title>
            <year>2018</year>
            <abstract>In official statistics there is an increasing demand for indicators at a higher frequency than those that have traditionally been observed. Direct measures of indicators at a high frequency can be very costly and difficult to achieve sometimes resulting in low quality results when the information set is not adequate. In such situations temporal disaggregation techniques can constitute a feasible alternative to the direct estimation of high frequency indicators. Additionally, even when high frequency indicators can be directly compiled, they are often not consistent over time with lower frequency versions. For example, annual surveys with larger samples may give more accurate estimates of the level of a variable compared to estimates from a small monthly survey that is designed to provide estimates of monthly change. Under the hypothesis that low frequency indicators are more reliable than high frequency ones, benchmarking techniques can be used to ensure the time consistency between high and low frequency indicators. Finally, directly or indirectly measured high frequency indicators may not necessarily meet required accounting and aggregation constraints. If that low frequency indicators meet accounting and aggregation constraints, reconciliation techniques can be used to restore them on high frequency indicators too.
Eurostat and the European Statistical System (ESS) developed these guidelines to help data producers derive high frequency data (e.g. quarterly or monthly) from low frequency data (e.g. annual) and to address related temporal and accounting constraints. Typical applications are known as temporal disaggregation, benchmarking, and reconciliation. The guidelines identify best practice to: (i) achieve harmonization across national processes; (ii) enhance comparability between results; (iii) ensure consistency across domains and between aggregates and their components.
The establishment of common guidelines for temporal disaggregation within the European Statistical System (ESS) is an essential step towards better harmonization and comparability of official statistics, especially in macroeconomic indicators and labour market statistics. These guidelines address the need for harmonization expressed by users from European and National Institutions. This document presents both theoretical aspects and practical implementation issues in a user friendly and easy to read framework. They meet the requirement of principle 7 (Sound Methodology) of the European Statistics Code of Practice (CoP), and their implementation is consistent with principles 14 (Coherence and Comparability) and 15 (Accessibility and Clarity). The guidelines also provide transparency of temporal disaggregation, benchmarking and reconciliation practices by encouraging documentation and dissemination of practices. These guidelines are complementary to the ESS guidelines on seasonal adjustment (Eurostat, 2015 edition), the ESS guidelines on revision policy for PEEIs (Eurostat, 2013 edition), and the Eurostat and United Nations handbook on rapid estimates. They are also in line with the Handbook on quarterly national accounts (Eurostat, 2013 edition).</abstract>
            <doi>10.2785/846595</doi>
            <url>https://ec.europa.eu/eurostat/documents/3859598/9441376/KS-06-18-355-EN.pdf</url>
        </manual>
    </entry>
    <entry id="BIM18">
        <incollection>
            <author>Buono, D. and Infante, E. and Mazzi, G. L.</author>
            <title>Short versus long time series: {A}n empirical analysis</title>
            <booktitle>Handbook on {S}easonal {A}djustment</booktitle>
            <publisher>#P_POEU#</publisher>
            <year>2018</year>
            <pages>669-680</pages>
            <abstract>Most of the literature on business cycle analysis relies, as input, on the seasonally adjusted (SA) data of the main economic indicators. The rationale is that the seasonal frequencies are different from the frequencies of the cycles, then seasonal movements do not carry useful information, moreover they can hide the information on the frequencies of interest in business cycle analysis. This idea is coherent with the literature on SA that rests on the hypothesis of orthogonality among the seasonal and the others components. For several reasons this hypothesis can fail and an interaction between seasonal and business cycles can arise. This work address the plausibility of this hypothesis and a first study on the effect that different seasonal adjustment algorithms can have on the business cycle analysis due to their different ability in separating the seasonal from the other frequencies. Empirically the evidence or the presence of interactions can be hardly detectable. There are several reasons: components are unobservable as well as their connections, consequently. Moreover, the series are often characterized by instability, and/or evolutionary behaviour of the components. Aim of this work can be summarized in: empirical investigation of the effects of a variety of SA methods on two aspects: the cyclical shape of the series and the turning point dating. The focus is on the growth cycle. The approach will be historical, and then no real time exercises is run.</abstract>
            <doi>10.2785/941452</doi>
            <url>https://ec.europa.eu/eurostat/documents/3859598/8939616/KS-GQ-18-001-EN-N.pdf</url>
        </incollection>
    </entry>
    <entry id="VTL18">
        <manual>
            <author>Capaccioli, M. and Gramaglia, L. and Pellegrino, M.</author>
            <title>Validation and {T}ransformation {L}anguage user and reference {M}anual</title>
            <organization>Statistical Data and Metadata eXchange (SDMX)</organization>
            <year>2018</year>
            <url>https://sdmx.org/wp-content/uploads/VTL-2.0-package-2018.07.12.zip</url>
        </manual>
    </entry>
    <entry id="Florescu18">
        <inproceedings>
            <author>Florescu, D. C.</author>
            <title>European structural farm statistics \textendash{} {N}ew quality rating system</title>
            <booktitle>#C_Quality#</booktitle>
            <year>2018</year>
            <note>\href{https://www.q2018.pl/wp-content/uploads/Sessions/Session%2019/Denisa%20Florescu/Session%2019_Denisa%20Florescu.pptx}{Online presentation}</note>
            <abstract>Eurostat, together with the statistical bodies belonging to the European Statistical System (ESS), has adopted a quality rating system to guide the dissemination of structural farm statistics derived from farm structure surveys. The system does this by showing when the estimates are sufficiently reliable to be published, either with or without a warning. It is based on: (i) coefficients of variations for totals and means of continuous variables; (ii) standard errors for proportions and counts. This paper also presents the work carried out to harmonise variance estimation methods and their application within the ESS. To apply the new quality rating system consistently, Eurostat and the national statistical bodies must compute roughly the same variance estimates. Future structural farm statistics will come from the data collected from 'Integrated Farm Statistics', based on a modular approach. This will lead to more complex national sampling designs. The paper also outlines ongoing developments towards integrating additional sampling design information specific to national multi-stage sampling in the estimation of variance. The paper also introduces new quality reporting based on the European Standard Quality Reporting System (ESQRS) template. This is of great help in assessing all quality dimensions, thereby improving the quality of EU data and metadata. Farm structure surveys are the main source of information on the current state of agriculture and the trends it is undergoing, required to monitor the common agricultural policy and other EU policies. High-quality data are essential for decision-makers.</abstract>
            <url>https://www.q2018.pl/wp-content/uploads/Sessions/Session%2019/Denisa%20Florescu/Session%2019_Denisa%20Florescu.DOCX</url>
        </inproceedings>
    </entry>
    <entry id="GLM18">
        <incollection>
            <author>Gatto, R. and Ladiray, D. and Mazzi, G. L.</author>
            <title>The effect of alternative seasonal adjustment methods on business cycle analysis</title>
            <booktitle>Handbook on {S}easonal {A}djustment</booktitle>
            <publisher>#P_POEU#</publisher>
            <year>2018</year>
            <pages>629-654</pages>
            <abstract>Seasonal adjustment procedures are usually designed for being applied on sufficiently long time series in order to obtain good quality results. This is due both to technical reasons such as the properties of the symmetric filters used and to non-technical ones such as the fact that, over a sufficiently long time period, components can be better identified and separated; consequently, the seasonal component can be more precisely estimated and eventually removed. In addition, long time series are required in order to read properly the statistics of the seasonality tests. Furthermore, on short time series the seasonality tests might be less robust. In official statistics, available time series associated to statistical indicators are often relatively short or subject to some shortening processes. This seems to contradict one of the main quality dimensions of statistics which is the coverage, but, at the same time, official statistics need to be continuously improved to better reflect the socio-economic structure. This process unavoidably leads to regularly adapting existing official statistics to evolving socio-economic structure. Furthermore better reflecting the current socio-economic situation can also require the development and the statistical compilation of new indicators, which at least in a first phase will cover only a limited time span. These two processes imply, at least temporarily, the availability of short time series associated to the statistical indicators.</abstract>
            <doi>10.2785/941452</doi>
            <url>https://ec.europa.eu/eurostat/documents/3859598/8939616/KS-GQ-18-001-EN-N.pdf</url>
        </incollection>
    </entry>
    <entry id="GLGM18">
        <inproceedings>
            <author>Grazzini, J. and Lamarche, P. and Gaffuri, J. and Museux, J.-M.</author>
            <title>"{S}how me your code, and then {I} will trust your figures": {T}owards software-agnostic open algorithms in statistical production</title>
            <booktitle>#C_Quality#</booktitle>
            <year>2018</year>
            <abstract>This contribution aims at further promoting the development and deployment of open, reproducible, reusable, verifiable, and collaborative computational resources in statistical offices regardless of the platform/software in use. Motivated by the consensus that data-driven evidence-based policymaking should be transparent, we argue that such approach is not only necessary for the practical implementation of statistical production systems, but also essential to reinforce the quality and trust of official statistics, especially in the context of a 'post-truth' society. We discuss some practical requirements to gear the continuous and flexible development and deployment of software components in production environments. Together with the adoption of some best practices derived from the open source community and the integration of new technological solutions, we propose to unleash the social power of open algorithms so as to create new participatory models of interaction between produsers that can contribute to a more holistic and extensive approach to production systems. Overall, a greater transparency in designing production processes is expected to result in a better grip on the quality of the statistical processes involved in data-driven policy-making. We illustrate this flexible and agile approach with various open, stand-alone software or source code used in statistical production environments at Eurostat.</abstract>
            <doi>10.5281/zenodo.3240282</doi>
            <url>https://www.researchgate.net/publication/325320551_Show_me_your_code_and_then_I_will_trust_your_figures_Towards_software-agnostic_open_algorithms_in_statistical_production</url>
        </inproceedings>
    </entry>
    <entry id="GMH18">
        <inproceedings>
            <author>Grazzini, J. and Museux, J.-M. and Hahn, M.</author>
            <title>Empowering and interacting with statistical produsers: {A} practical example with {E}urostat data as a service</title>
            <booktitle>#C_CESS#</booktitle>
            <year>2018</year>
            <abstract>While the importance of openness and transparency in statistical processes, and how these can be supported through open algorithms and open data, has been already emphasized, this contribution aims at showcasing an approach where algorithms and data are delivered as interactive, reusable and reproducible computing services. This will eventually provide produsers with the necessary tools to perform, for themselves, data analytics on Eurostat data in a straightforward manner.</abstract>
            <doi>10.5281/zenodo.3240557</doi>
            <url>https://www.researchgate.net/publication/325973362_Empowering_and_interacting_with_statistical_produsers_a_practical_example_with_Eurostat_data_as_a_service</url>
        </inproceedings>
    </entry>
    <entry id="Liotti18">
        <article>
            <author>Liotti, A.</author>
            <title>Experiences in application of the {E}uropean {S}tatistical {S}ystem {B}usiness {R}egisters recommendations manual</title>
            <journal>#J_SJIAOS#</journal>
            <year>2018</year>
            <volume>34</volume>
            <number>3</number>
            <pages>313-316</pages>
            <abstract>he main objectives of the Manual are: To provide guidelines for implementation of the EU Regulation; To support the harmonisation between the registers in the various Member States; To explain the Regulation's provisions. A recent survey has established that the statisticians in the European Statistical System dealing with the maintenance and development of national Statistical Business Registers find useful that they can find in the Manual the information necessary to allow the correct and consistent interpretation of the Regulation and recommendations on best practices of various countries in building and operating registers and in treatment of special cases. Users also appreciate that each chapter is capable of being read separately, whilst still forming part of a coherent set. The EU Regulation also legislates on the exchange of confidential data. This was the pillar on which was built the EuroGroups Register of multinational enterprise groups, managed by Eurostat with the participation of all European countries. A revision of the Manual will be necessary, in order to take on board the provisions of the upcoming new Regulation, as well as some new recommendations originated by the on-going Data Quality Programme for the Statistical Business Registers in the European Statistical System.</abstract>
            <doi>10.3233/SJI-170401</doi>
            <url>https://content.iospress.com/download/statistical-journal-of-the-iaos/sji170401?id=statistical-journal-of-the-iaos%2Fsji170401</url>
        </article>
    </entry>
    <entry id="MPMKB18">
        <techreport>
            <author>Marcellino, M. G. and Papailias, F. and Mazzi, G. L. and Kapetanios, G. and Buono, D.</author>
            <title>Big data econometrics: {N}ow casting and early estimates</title>
            <institution>BAFFI-CAREFIN Centre</institution>
            <year>2018</year>
            <number>82</number>
            <note>Research Paper Series</note>
            <abstract>This paper aims at providing a primer on the use of big data in macroeconomic nowcasting and early estimation. We discuss: (i) a typology of big data characteristics relevant for macroeconomic nowcasting and early estimates, (ii) methods for features extraction from unstructured big data to usable time series, (iii) econometric methods that could be used for nowcasting with big data, (iv) some empirical nowcasting results for key target variables for four EU countries, and (v) ways to evaluate nowcasts and ash estimates. We conclude by providing a set of recommendations to assess the pros and cons of the use of big data in a specic empirical nowcasting context.</abstract>
            <url>https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3206554</url>
        </techreport>
    </entry>
    <entry id="MRR18">
        <inproceedings>
            <author>Martins Ferreira, P. and R\'emond-Tiedrez, I. and Rueda-Cantuche, J. M.</author>
            <title>{QDR} methodology: {U}nderstanding bilateral trade flows in the {E}uropean {U}nion</title>
            <booktitle>#C_IIOC#</booktitle>
            <year>2018</year>
            <note>\href{https://www.iioa.org/conferences/26th/papers/files/3338.pdf}{Online abstract}</note>
            <abstract>Trade asymmetry has been a well-known fact and there are extensive literature and reports about the causes for those asymmetries. There is also a  recognised effort made by trade statisticians for mitigate trade asymmetry over time. Notwithstanding the positive achievements that have been made so far, to build an Inter-Country Supply, Use and Input-Output tables (IC-SUIOT) we more than low trade asymmetry: we need no trade asymmetry at all. The European Statistical System (ESS) has an extensive and rich amount of trade data and a lot of resources are devoted to measure trade flows. Nevertheless, the customs union of the EU adds another challenge regarding trade in goods statistics: Member-States declare imports/exports for customs or tax purposes without thisMember State having acquired ownership of the goods,  i.e. declare quasi-transit as well. While relevant  for physical  flow of  trade, quasi-transit and re-exports distort the geographical economic relationship among Member-States and therefore they should be identified and taken into account in the framework of IC-SUIOT. QDR methodology was developed in order to address the specificities of trade in goods in EU by providing a way to estimate  consolidated trade flows, i.e. solving trade asymmetries, between two countries by three types of trade: quasi-transit (Q), domestic (D) and re-export (R). For quasi-transit and re-exports the intermediary country between that takes part of the physical  flow between origin and destination is also identified. QDR methodology was used in FIGARO project and it revealed very useful for identifying  relevant trade relationships within countries.</abstract>
            <url>https://www.iioa.org/conferences/26th/papers/files/3348_20180515021_iioa2018_QDR.pdf</url>
        </inproceedings>
    </entry>
    <entry id="Ricciato18">
        <inproceedings>
            <author>Ricciato, F.</author>
            <title>Towards a reference methodological framework for processing {MNO} data for {O}fficial {S}tatistics</title>
            <booktitle>#C_GFTS#</booktitle>
            <year>2018</year>
            <abstract>Mobile network signalling data, captured from the continuous interaction of mobile terminals with the cellular network, have better spatial/temporal resolution than traditional Call Detail records (CDR). However, their format and semantic are intimately connected with network-specific technical aspects. For this reason, such data are considerably more complex and have a higher degree of heterogeneity across different Mobile Network Operators (MNO). It is difficult for experts outside the telecommunication domains, such as e.g. statisticians, to interpret and manipulate such data directly. In the proposed contribution we present a general Reference Methodological Framework (RMF) intended to facilitate the use of signalling data by statisticians. The RMF is inspired by the principles of functional layering and by the "hour-glass model", which lie at the foundation of modern computer network architectures. The RMF encompasses a convergence layer that decouples the complexity of signalling data at the bottom from the statistical definitions on the top. This allows experts from the two domains, MNO engineers and statisticians, to work independently and eases the evolution of the two layers.This paper presents the general principles underlying the RMF, the role and responsibilities of the different actors in transforming elemental data into meaningful and relevant statistical concepts, provides a concrete actionable proposal and presents early results from its application in a pilot project conducted in collaboration between Eurostat and one European MNO. We highlight lessons learned and give an outlook for the future development and implementation of the RMF and its application to tourism statistics and other areas of statistics.</abstract>
            <url>http://www.15th-tourism-stats-forum.com/pdf/Papers/S3/3_1_A_Reference_Methodological_Framework_for_processing_mobile_network_operatordata_for_official_statistics.pdf</url>
        </inproceedings>
    </entry>
    <entry id="RDWSS18">
        <inproceedings>
            <author>Ricciato, F. and De Meersman, F. and Wirthmann, A. and Seynaeve, G. and Skaliotis, M.</author>
            <title>Processing of {M}obile {N}etwork {O}perator data for {O}fficial {S}tatistics: {T}he case for public-private partnerships</title>
            <booktitle>#C_DGINS#</booktitle>
            <year>2018</year>
            <note>\href{http://www.dgins2018.ro/wp-content/uploads/2018/10/17-MNO-data-for-Official-Statistics-DGINS_v35b_final-1.pdf}{Online presentation}</note>
            <abstract>This paper discusses various aspects related to the potential partnership between Statistical Offices (SO) and Mobile Network Operators (MNO) to leverage MNO data for the computation of official statistics.MNO data are complementary to other data sources that are already available to SOs (e.g., survey data, administrative registers)and  their combination can lead to a new generation of statistical products, delivered more timely and with better spatio-temporal resolution than traditional statistics. This enables statisticians to gain more accurate and up-to-date insight into various aspects of human mobility and related socio-economic phenomena (e.g., tourism flows, presence and residence, commuting patterns, use of transportation means among others) with clear advantages for the process of policy design and evaluation based on such statistics.The cooperation between SO and MNO can be designed to prevent potential conflicts  between the  public and  private interests, e.g. by the provision of adequate protection for business  confidentiality, methodological quality  and process transparency. We argue that partnering with SO brings direct and indirect benefits also to the MNOs, particularly in terms of empowering the portfolio of commercial analytic products they can offer to business customers. Synergies between the production of official statistics and commercial analytic products can be positively leveraged within the framework of a well-designed partnership model. By doing so, the SO-MNO partnership does not represent as a risk to the MNO business nor a diminution of the role and independency of SO, but rather as an additional opportunity for both sides. While the focus of this paper is on partnership models between SOs and MNOs, many elements of the discussion apply as well to private data holders from other sectors, and may contribute to advance the future vision of public-private partnerships for joint data analytics.</abstract>
            <url>http://www.dgins2018.ro/wp-content/uploads/2018/10/17-MNO-data-for-Official-Statistics-DGINS_v35b_final.pdf</url>
        </inproceedings>
    </entry>
    <entry id="RSWGR18">
        <inproceedings>
            <author>Ricciato, F. and Skaliotis, M. and Wirthmann, A. and Giannakouris, K. and Reis, F.</author>
            <title>Towards a reference architecture for {T}rusted {S}mart {S}tatistics</title>
            <booktitle>#C_DGINS#</booktitle>
            <year>2018</year>
            <abstract>In this contribution we outline the concept of Trusted Smart Statistics as the natural evolution of official statistics in the new datafied world, where traditional data sources (survey and administrative data) represent a valuable but small portion of the global data stock, much thereof being held in the private sector. In order  to  move towards practical implementation of this vision a Reference Architecture for Trusted Smart Statistics is required, i.e., a coherent system of technical, organisational and legal means combined to provide an articulated set of trust guarantees to all involved players. In this paper we take a first  step in this direction by proposing selected design principles and system components that, as of the current state of play, we believe will be part of the final design. The goal of this contribution is not to propose a ready-made fully-fledged solution, but rather build awareness about the necessary elements (technological and not) and fuel the discussion with the relevant stakeholders.</abstract>
            <url>https://www.researchgate.net/publication/328215827_Towards_a_Reference_Architecture_for_Trusted_Smart_Statistics</url>
        </inproceedings>
    </entry>
    <entry id="RRB18">
        <article>
            <author>Rueda-Cantuche, J. M. and R\'emond-Tiedrez, I. and Bouwmeester, M. C.</author>
            <title>Institutionalization of inter-country input-output tables: {W}orking towards harmonization and standardization</title>
            <journal>#J_JIE#</journal>
            <year>2018</year>
            <volume>22</volume>
            <number>3</number>
            <pages>485-486</pages>
            <abstract>Effective policy to encourage sustainable production and consumption is needed to shape the future so that our impact stays in line with the earth's carrying capacity. To design and monitor effective policy, good-quality data are indispensable. Production and consumption are two sides of the same coin, and in today's globalized world, an integrated and consistent inter-country accounting framework that links these two is a necessity for adequate analysis. A better understanding of global value chains starts with capturing production and trade relations in a coherent and complete system. More insight in the environmental impact of consumption requires an integrated environmental-economic accounting framework. Although producers generally are the ones to pay the wages, extract the resources, and emit the greenhouse gases - our productive system is in place to serve our consumer society. More awareness of the impact of consumption, at home and abroad, is needed to change our behaviour and create a sustainable economy.</abstract>
            <doi>10.1111/jiec.12761</doi>
            <url>https://onlinelibrary.wiley.com/doi/epdf/10.1111/jiec.12761</url>
        </article>
    </entry>
    <entry id="RRVMRVAR18">
        <inproceedings>
            <author>Rueda-Cantuche, J. M. and R\'emond-Tiedrez, I. and Velazquez-Afonso, A. and Martins Ferreira, P. and Rocchi, P. and Valderas Jaramillo, J. M. and Amores, A. F. and Roman, M. V.</author>
            <title>From theory to practice: {W}hat makes the {E}uropean {U}nion’s inter-country supply, use and input-output tables different?</title>
            <booktitle>#C_IIOC#</booktitle>
            <year>2018</year>
            <note>\href{https://www.iioa.org/conferences/26th/papers/files/3338.pdf}{Online abstract}</note>
            <abstract>The  Eurostat-JRC  project  "Full  International  and  Global  Accounts  for  Research  in  Input-Output Analysis" (FIGARO) has produced experimental  EU-Inter Country Supply, Use and Input-Output Tables for the year 2010 in line with the ESA 2010 methodology. Setting up a European Inter-country  Supply, Use and Input-Output Table implies the compilation of a balanced view of international trade consistent with National Accounts data. It is therefore absolutely necessary to: (a) reconcile the trade asymmetries and provide one single trade flow for each bilateral transaction between partners; and (b) align the trade figures with National Accounts data, in order to capture, for instance, the potential environmental, social and economic effects of supply and demand shocks on the national economies via the existing global  value (and supply) chains. The paper describes methodological issues raised by the construction process of the Inter-country Supply, Use and Input-Output Tables: e.g. econometric estimations  of  cif/fob margins; econometric estimations of missing bilateral services trade; alignment of trade statistics and national accounts data: e.g. goods sent abroad for processing, merchanting activities.</abstract>
            <url>https://www.iioa.org/conferences/26th/papers/files/3338_20180515031_iioa2018_FIGARO_main.pdf</url>
        </inproceedings>
    </entry>
    <entry id="RRAVR18">
        <inproceedings>
            <author>Rueda-Cantuche, J. M. and Roman, M. V. and Amores, A. F. and Valderas Jaramillo, J. M. and R\'emond-Tiedrez, I.</author>
            <title>Employment effects of {EU} services exports to the rest of the world by modes of supply using the {E}urostat's {EU} inter-country input-output tables</title>
            <booktitle>#C_IIOC#</booktitle>
            <year>2018</year>
            <abstract>Services are increasingly delivered across borders under various modes of supply and gaining higher shares over all the economic activities.  However, the availability of statistics on the international supply of services detailed by services category, mode of supply and partner country is limited  and at the same time critically important for trade policy making. Based on the most recent Eurostat published data, this paper presents the first attempt to estimate the employment effects by modes of supply using official statistics and the Eurostat's experimental EU Inter-country Input-Output Table (FIGARO Project).</abstract>
            <url>https://www.iioa.org/conferences/26th/papers/files/3345.pdf</url>
        </inproceedings>
    </entry>
    <entry id="SM18">
        <inproceedings>
            <author>Salvati, M. and M\'esz\'aros, M.</author>
            <title>Introduction to "flagr"</title>
            <booktitle>#C_uRos#</booktitle>
            <year>2018</year>
            <abstract>The object of this paper is to present the R package 'flagr' that is in development in Eurostat for facilitating the internal revision of the use of flags and flagging of aggregates in dissemination. The 'flagr' package provides general functions following the methodological guidelines suggested by the SDMX for the aggregate. The package provides three different functions how the individual flags can be transferred to the aggregate.The first one is the hierarchy of the SDMX flags suggested by the implementation guidelines. This method compares all flags of a given dataset and keeps the flag for the aggregate with the highest score on the SDMX hierarchy or in a personally specified order. The second method counts the occurrences of the flags in the underlying data and the flag for the aggregate will be the flag that has the highest count. The last method not only counts the frequency of a flag is represented in the dataset, but also it also it takes into account the weight of the individual values, as the contribution of the corresponding individual value to the aggregate. The flag, which has the highest summed weight, is used for the flag of the aggregate if it is above a certain threshold.</abstract>
            <url>http://r-project.ro/conference2018/uRos2018.pdf#page=54</url>
        </inproceedings>
    </entry>
    <entry id="VM18">
        <inproceedings>
            <author>V\^aju, S. C. and M\'esz\'aros M.</author>
            <title>Administrative data and quality \textendash{} {G}uidelines towards better quality of administrative data</title>
            <booktitle>#C_Quality#</booktitle>
            <year>2018</year>
            <note>\href{https://www.q2018.pl/wp-content/uploads/Sessions/Session%2037/M%C3%A1ty%C3%A1s%20M%C3%A9sz%C3%A1ros/Session%2037_Matyas%20Meszaros.pptx}{Online presentation}</note>
            <abstract>Statistical authorities need to produce data faster in a cost effective way, to become more responsive to users' demands, while at the same time providing high quality output. One way to fulfil this is to make more use of already available data sources, and in particular administrative sources, most typically used in combination with other sources. Depending on the use of the administrative sources and the data configuration different statistical tasks must be applied. Usually it is not only one task but a sequence of different tasks that have to be applied, for example, data integration, imputation and editing or tabulation. For these tasks different methods are available and depending on the input data quality and the data configuration the same method can have limited use or produce lower quality outputs. The use of administrative data sources risks impacting negatively quality on several dimensions, in particular accuracy and comparability. Surveys and administrative sources have both particular strengths and weaknesses. Combining them may overcome these weaknesses, provided that suitable methodology and tools are used. At the same time, harmonised measures of quality for outputs that combine administrative sources with other sources (surveys) are necessary to ensure that European Union official statistics are of sufficient quality and fit for their intended use. This paper looks at the most frequent methodological challenges faced when integrating administrative sources and provides, for typical situations, preferred methods to have the best quality of statistical output. It also introduces the work of ESSnet on the Quality of Multisource Statistics (KOMUSO) to develop quality measures and guidelines related to the use of administrative sources.</abstract>
            <url>https://www.q2018.pl/wp-content/uploads/Sessions/Session%2037/M%C3%A1ty%C3%A1s%20M%C3%A9sz%C3%A1ros/Session%2037_Matyas%20Meszaros.docx</url>
        </inproceedings>
    </entry>
    <entry id="VRPS18">
        <article>
            <author>Vanhoof, M. and Reis, F. and Ploetz, T. and Smoreda, Z.</author>
            <title>Assessing the quality of home detection from mobile phone data for official statistics</title>
            <journal>#J_JOS#</journal>
            <year>2018</year>
            <volume>34</volume>
            <number>4</number>
            <pages>935-960</pages>
            <abstract>Mobile phone data are an interesting new data source for official statistics. However, multiple problems and uncertainties need to be solved before these data can inform, support or even become an integral part of statistical production processes. In this article, we focus on arguably the most important problem hindering the application of mobile phone data in official statistics: Detecting home locations. We argue that current efforts to detect home locations suffer from a blind deployment of criteria to define a place of residence and from limited validation possibilities. We support our argument by analysing the performance of five home detection algorithms (HDAs) that have been applied to a large, French, Call Detailed Record (CDR) data set (~18 million users, five months). Our results show that criteria choice in HDAs influences the detection of home locations for up to about 40% of users, that HDAs perform poorly when compared with a validation data set (resulting in 358-gap), and that their performance is sensitive to the time period and the duration of observation. Based on our findings and experiences, we offer several recommendations for official statistics. If adopted, our recommendations would help ensure more reliable use of mobile phone data vis-à-vis official statistics.</abstract>
            <doi>10.2478/jos-2018-0046</doi>
            <url>https://content.sciendo.com/view/journals/jos/34/4/article-p935.xml</url>
        </article>
    </entry>
    <entry id="VRRR18">
        <inproceedings>
            <author>Velazquez-Afonso, A. and Rocchi, P. and Rueda-Cantuche, J. M. and R\'emond-Tiedrez, I.</author>
            <title>Making the circle square: treatment of goods sent abroad for processing in the construction of the {E}uropean {U}nion’s inter-country supply, use and input-output tables</title>
            <booktitle>#C_IIOC#</booktitle>
            <year>2018</year>
            <note>\href{https://www.iioa.org/conferences/26th/papers/files/3347.pdf}{Online abstract}</note>
            <abstract>The extension from national to inter-country Supply, Use and Input-Output tables (SUIOTs) consists in splitting national SUTs domestic exports (FOB) by country of destination (and importing industry) and by type of use (intermediate or final), which in turn produces indirect estimations of imports of intermediate and final goods and services among countries of origin (and exported products). It could also be the other way round, splitting national SUTs imports by countries of origin, as in the WIOD approach. The two approaches should not differ, in principle, as long as the view of bilateral  trade among countries is balanced at the level of each good and service and both exports and imports are valued in FOB. However, this is not the case in official statistics, mostly due to trade asymmetries and the different valuation of exports (FOB) and imports (CIF). This  paper however justifies the  first choice for various reasons and put a special focus on the treatment of goods sent  abroad  for processing, including some indications about the necessary assumptions made in the absence of official data about trading partners and type and destination of the processed goods.</abstract>
            <url>https://www.iioa.org/conferences/26th/papers/files/3347_20180515071_iioa2018_FIGARO_GSA.pdf</url>
        </inproceedings>
    </entry>
    <entry id="AFMMV17">
        <article>
            <author>Aprigliano, V. and Foroni, C. and Marcellino, M. and Mazzi, G. and Venditti, F.</author>
            <title>A daily indicator of economic growth for the {E}uro area</title>
            <journal>#J_IJCEE#</journal>
            <year>2017</year>
            <volume>7</volume>
            <pages>43-63</pages>
            <abstract>In this paper, we study alternative methods to construct a daily indicator of growth for the euro area. We aim for an indicator that (i) provides reliable predictions, (ii) can be easily updated at the daily frequency, (iii) gives interpretable signals, and (iv) it is linear. Using a large panel of daily and monthly data for the euro area we explore the performance of two classes of models: bridge and U-MIDAS models, and different forecast combination strategies. Forecasts obtained from U-MIDAS models, combined with the inverse MSE weights, best satisfy the required criteria.</abstract>
            <doi>10.1504/IJCEE.2017.080636</doi>
            <url>http://www.igier.unibocconi.it/files/570.pdf</url>
        </article>
    </entry>
    <entry id="BSEMA17">
        <article>
            <author>Brandmueller, T. and Sch{\"a}fer, G. and Ekkehard, P. and M{\"u}ller, O. and Angelova-Tosheva, V.</author>
            <title>Territorial indicators for policy purposes: {NUTS} regions and beyond</title>
            <journal>#J_RS#</journal>
            <year>2017</year>
            <volume>7</volume>
            <number>1</number>
            <pages>78-89</pages>
            <abstract>Regional statistics, along with the NUTS (Nomenclature des Unités Territoriales Statistiques, or Nomenclature of Territo-rial Units for Statistics) classification, al-ready have a solid tradition. They have developed into a very useful tool for de-tailed analyses and have become the basis for important decisions in the allocation of EU funding. Gradually, the scope of regional statistics has widened, and re-gional statistics now play a role in several statistical domains with a wide range of statistical indicators. The recognition that many of the social and economic issues Europe faces today have urban or rural characteristics has led to an initiative to supplement statistical da-ta on NUTS regions with data on cities and rural areas. These sub-national statistics allow policy makers to better target their policies. For example, in some parts of Eu-rope, poverty and social exclusion are clear-ly an urban problem, while in other areas they are primarily a rural problem. A further aspect that has gained considera-ble importance in territorial policy making - as well as in public awareness - concerns the so-called functional regions, which are selected or constructed from more detailed geographical units according to specific features. The labour market area is one ex-ample of this type of functional delinea-tion, which helps to shed light on im-portant territorial characteristics. The fast-growing use of geographic in-formation and new technical facilities has created possibilities for merging statistics and related geographical information into so-called spatial statistics. An example is grid-based population data, which helps to determine the concrete locations of peo-ple with access to certain facilities (e.g. public transport, airports) or to identify a population close to the sea. Through the intensive use of map-related functions, the utility of regional and urban statistics can also be enhanced, and different statistics can be combined. This paper argues that different sub-national statistics offer different but inter-related perspectives. They can be com-bined in multiple ways to create new pos-sibilities for policy analysis and to illus-trate social and economic characteristics at varying levels of geographic detail.</abstract>
            <doi>10.15196/RS07105</doi>
            <url>http://www.ksh.hu/docs/hun/xftp/terstat/2017/rs070105.pdf</url>
        </article>
    </entry>
    <entry id="Bujnowska17">
        <inproceedings>
            <author>Bujnowska, A.</author>
            <title>Statistical confidentiality in {E}uropean business statistics</title>
            <booktitle>#W_SDC#</booktitle>
            <year>2017</year>
            <organization>#O_UNECE#</organization>
            <url>https://www.unece.org/fileadmin/DAM/stats/documents/ece/ces/ge.46/2017/1_confidentiality_europe.pdf</url>
        </inproceedings>
    </entry>
    <entry id="BAR17">
        <techreport>
            <author>Buono, D. and Amores, A. F. and R\'emond-Tiedrez, I.</author>
            <title>Data analytics: {E}uropean wheel of competitiveness</title>
            <institution>#O_EC_ESTAT#</institution>
            <year>2017</year>
            <note>Statistical Working Papers</note>
            <abstract>This study aims to realize a statistical analysis of competitiveness in the EU-28 based on a statistical reference framework, previously defined as the European Wheel of Competitiveness. This framework comprises a list of 35 indicators (EWoC indicators) related to macroeconomics, microeconomics, globalization, environment and socio-institutional aspects. The analytical methods for this study were established in line with the Statistical reference framework for competitiveness analysis in the EU-28 Member States. As a rather broad concept, competitiveness can be described by a large set of different factors and definitions. The aim of this analysis is to show possible redundancy between indicators, but also possible explanatory power. Moreover, it tests the initial assumption that the largest principal components will be sufficient to explain the variability in the observed dataset. Finally, it detects possible patterns based on available set of indicators. Results confirmed some well-known correlations. For instance, the unemployment rate is positively correlated with the indicator People at risk of poverty or social exclusion (AROPE), which is also negatively correlated with the Real GDP per capita. Nevertheless, the performed correlation analysis did not provide any substantial results regarding some other expected correlations. It has to be mentioned at this point that, the presence or the absence of correlation results between several indicators of the set of EWoC indicators, is a fact that should not be understand as a weakness of the EWoC framework but rather as a strength due to the fact that there is not redundant information. Exploring the high correlations between the aforementioned indicators and indicators by themselves, it was decided to control for the indicator 4. Concerning the results obtained with partial correlation analysis, it was evident that most of the previously captured correlation actually comes from the Gross domestic expenditure on R\&amp;D. More precisely, when controlling the correlation for the aforementioned indicator, the correlation across EWoC indicators becomes weaker or insignificant in almost all cases. For that reason, and other reasons detailed in the article, indicator 4 was not used for the latter analysis. Finally, the correlation analysis showed that indicator 34: Control of corruption could be also removed from the set of the EWoC indicators. The cross-correlation analysis explored time series correlation and showed that for the same pair of indicators, different or opposite correlation results can be obtained. This proved that countries may react differently and in several periods in time, to similar economic changes. This result provided the idea of countries clustering. In addition, obtained correlation coefficients vary from country to country. Therefore, it was of interest to look for the evidence of formation of groups of countries. In another words, the country-clusters. EU-28The performed analysis showed that the "old" EU Member States (France, Germany, United Kingdom, Italy...) form a cluster while the Eastern EU countries, i.e. "newest"Member States (Estonia, Latvia, Lithuania, Poland, Bulgaria, Romania, Croatia...) form a separate cluster. It is also noteworthy the fact that Luxembourg stands out as being very different, insofar as it forms its own cluster (Figure 1). The explored dataset consists of 29 indicators for time span 2000-2014. Therefore, it seemed logic to examine opportunities for the reduction of dimensionality or indicators` grouping. All analysis (Principal Components, k-means cluster analysis and Gaussian mixture model and the Hierarchical agglomerative clustering analysis) showed that indicators, either as a component of one linear combination or as a member of one group, can be classified into 4 groups. It is noteworthy the fact that indicator 29: Real GDP per capita stands out as being different, insofar as it forms its own cluster</abstract>
            <doi>10.2785/550234</doi>
            <url>https://op.europa.eu/en/publication-detail/-/publication/5ce64720-41ed-11e8-b5fe-01aa75ed71a1/language-en</url>
        </techreport>
    </entry>
    <entry id="BMKMP17">
        <article>
            <author>Buono, D. and Mazzi, G. L. and Kapetanios, G. and Marcellino, M. and Papailias, F.</author>
            <title>Big data types for macroeconomic nowcasting</title>
            <journal>#J_EURONA#</journal>
            <year>2017</year>
            <volume>1</volume>
            <pages>67-77</pages>
            <abstract>In this paper we present a detailed discussion on various types of big data which can be useful in macroeconomic nowcasting. In particular, we review the big data sources, availability, specific characteristics and their use in the literature. We conclude this paper identifying the big data types which could be adopted for real applications.</abstract>
            <url>https://ec.europa.eu/eurostat/cros/system/files/euronaissue1-2017-art4.pdf</url>
        </article>
    </entry>
    <entry id="Capaccioli17">
        <inproceedings>
            <author>Capaccioli, M.</author>
            <title>The {E}urostat {P}rocess {M}anagement {F}ramework</title>
            <booktitle>#W_IEQO#</booktitle>
            <year>2017</year>
            <organization>#O_UNECE#</organization>
            <abstract>The statistical organisations are facing several challenges: their mission is evolving, the budget and human resources are shrinking and new IT technologies are appearing on the market. They need to improve their rapidity to respond to new user requirements and maintain at the same time  high quality products and services. In this context, managing business processes is an important sign of maturity and efficiency in organisations. Eurostat has decided to launch the project Process Management Framework (PMF) with the objective to build a harmonised documentation of  the Eurostat processes, increase the process management maturity and create a pool of competence for business process modelling. This project is strongly linked with the Quality review initiative undertaken by Eurostat.</abstract>
            <url>http://www.unece.org/fileadmin/DAM/stats/documents/ece/ces/ge.58/2017/mtg4/Paper_5_-_PMF_Eurostat.pdf</url>
        </inproceedings>
    </entry>
    <entry id="GL17">
        <inproceedings>
            <author>Grazzini, J. and Lamarche, P.</author>
            <title>Production of social statistics... goes social!</title>
            <booktitle>#C_NTTS#</booktitle>
            <year>2017</year>
            <abstract>The scope of this paper is to present a practical framework adopted for the integration of software applications into a statistical production chain. The focus is the actual implementation of a high-level collaborative platform aiming not only at producing social statistics, but also at further fostering experimentation and analysis in that field. In doing so, we strongly support the (obvious) claim that "the modernisation and industrialisation of official statistical production needs a unified combination of statistics and computer science in its very principles". Motivated by the consensus that processes - in particular statistical processes - for data-driven policy should be transparent, we naturally promote open, reproducible, reusable, verifiable, and collaborative software development and deployment in a statistical organisation. Beyond just devising guidelines and best practices, we show how the platform is implemented for the production of social statistics. For that purpose, we adopt a reasonable mix of bottom-up (from low-level scope to high-level vision) and top-down (from black-box process models to traceable functional modules) designs, so as to "think global, [and] act local". In building the parts while planning the whole, we provide with a flexible and agile approach to immediate needs and current legacy issues, as well as long-term problems and potential future requirements for statistical production.</abstract>
            <doi>10.5281/zenodo.3240501</doi>
            <url>https://www.researchgate.net/publication/324208747_Production_of_social_statistics_goes_social</url>
        </inproceedings>
    </entry>
    <entry id="HS17">
        <article>
            <author>Hagsten, E. and Sabadash, A.</author>
            <title>A neglected input to production: {T}he role of {ICT}-schooled employees in firm performance</title>
            <journal>#J_IJM#</journal>
            <year>2017</year>
            <volume>38</volume>
            <number>3</number>
            <pages>373-391</pages>
            <abstract>The purpose of this paper is to broaden the perspective on how information and communication technology (ICT) relates to productivity by introducing a novel ICT variable: the share of ICT-schooled employees in firms, an intangible input often neglected or difficult to measure.</abstract>
            <doi>10.1108/IJM-05-2015-0073</doi>
            <url>https://www.emerald.com/insight/content/doi/10.1108/IJM-05-2015-0073/full/pdf?title=a-neglected-input-to-production-the-role-of-ict-schooled-employees-in-firm-performance</url>
        </article>
    </entry>
    <entry id="HMKK17">
        <article>
            <author>Hamadeh, N. and Mouyelo-Katoula, M. and Konijn, P. and Koechlin, F.</author>
            <title>Purchasing power parities of currencies and real expenditures from the international comparison program: {R}ecent results and uses</title>
            <journal>#J_SIR#</journal>
            <year>2017</year>
            <volume>131</volume>
            <number>1</number>
            <pages>23-42</pages>
            <abstract>The International Comparison Program (ICP) is a worldwide statistical initiative designed to estimate purchasing power parities (PPPs) that can be used as currency converters to compare the performance of countries around the world, thereby providing in-depth views of the distribution of resources worldwide. The 2011 round of the ICP was leveraged on the successful outcome of the 2005 round that included 146 countries, introducing various methodological improvements. The summary report and results from the 2011 round were released in April 2014 and provided PPPs, price levels indices, and expenditures in PPP terms for the GDP and major aggregates for 199 participating countries. More detailed results were released in June 2014 and a final comprehensive report in October 2014. The final report provided a more in-depth analysis of volume and per capita indices. The results stirred a strong debate among the user community because of their finding that the world has become more equal than previously thought. The purpose of this paper is to provide an overview of the main results and findings of ICP 2011, its governance framework and partnership with the Eurostat-Organization for Economic Co-operation and Development (OECD) PPP program, and the major methodological innovations that were implemented. The paper reviews the major uses of the PPPs generated by the ICP 2011 and the Eurostat-OECD PPP program, and concludes with thoughts about the future of the ICP.</abstract>
            <doi>10.1007/s11205-015-1215-z</doi>
            <url>https://link.springer.com/content/pdf/10.1007%2Fs11205-015-1215-z.pdf</url>
        </article>
    </entry>
    <entry id="KKLS17">
        <article>
            <author>Koechlin, F. and Konijn, P. and Lorenzoni, L. and Schreyer, P.</author>
            <title>Comparing hospitals and health prices and volumes across countries: {A} new approach</title>
            <journal>#J_SIR#</journal>
            <year>2017</year>
            <volume>131</volume>
            <number>1</number>
            <pages>43-64</pages>
            <abstract>Health services are among the most comparison-resistant services in international comparisons such as the Eurostat–OECD Purchasing Power Parities (PPP) program and the ICP. Traditionally, PPPs for health services are estimated on the basis of input methods, e.g. by comparing salaries of doctors and nurses. This mainly reflects the difficulties inherent in measuring the output of services produced by nonmarket producers. Since 2007, OECD and Eurostat have undertaken work, with their Member States, to develop explicit output-based measures of prices and volumes of hospital services directed at comparisons across countries. The approach is based on collecting quasi-prices for a basket of comparable and representative medical and surgical hospital services. Eurostat and OECD used the new approach for the first time in their PPP calculations that entered the 2011 ICP benchmark round. The paper describes the output-based approach, the way it was developed and tested to assess its feasibility, and the results based on the latest data collection.</abstract>
            <doi>10.1007/s11205-015-1196-y</doi>
            <url>https://link.springer.com/content/pdf/10.1007%2Fs11205-015-1196-y.pdf</url>
        </article>
    </entry>
    <entry id="PBS17">
        <article>
            <author>Pantea, S. and Biagi, F. and Sabadash, A.</author>
            <title>Are {ICT} displacing workers in the short run? {E}vidence from seven {E}uropean countries</title>
            <journal>#J_IEP#</journal>
            <year>2017</year>
            <volume>39</volume>
            <pages>36-44</pages>
            <abstract>This paper examines the short run labour substitution effects of using ICT at firm-level in the manufacturing and services sectors in seven European countries, during the period 2007–2010. The data come from a unique dataset provided by the ESSLait Project on Linking Microdata, which contains internationally comparable data based on the production statistics linked at firm level with the novel ICT usage indicators. We adopt a standard conditional labour demand model and control for unobservable time-invariant firm-specific effects. The results show that ICT use has a statistically insignificant labour substitution effect and this effect is robust across countries, sectors and measures of ICT use. Our findings suggest that increased use of ICT within firms does not reduce the numbers of workers they employ.</abstract>
            <doi>10.1016/j.infoecopol.2017.03.002</doi>
            <url>https://www.sciencedirect.com/science/article/pii/S0167624516301615</url>
        </article>
    </entry>
    <entry id="PMM17">
        <article>
            <author>Proietti, T. and Marczak, M. and Mazzi, G. L.</author>
            <title>Euro{MI}nd-{D}: {A} density estimate of monthly {G}ross {D}omestic {P}roduct for the {E}uro area</title>
            <journal>#J_JAE#</journal>
            <year>2017</year>
            <volume>32</volume>
            <number>3</number>
            <pages>683-703</pages>
            <abstract>EuroMInd-D is a density estimate of monthly gross domestic product (GDP) constructed according to a bottom-up approach, pooling the density estimates of 11 GDP components, by output and expenditure type. The components' density estimates are obtained from a medium-size dynamic factor model handling mixed frequencies of observation and ragged-edged data structures. They reflect both parameter and filtering uncertainty and are obtained by implementing a bootstrap algorithm for simulating from the distribution of the maximum likelihood estimators of the model parameters, and conditional simulation filters for simulating from the predictive distribution of GDP. Both algorithms process the data sequentially as they become available in real time. The GDP density estimates for the output and expenditure approach are combined using alternative weighting schemes and evaluated with different tests based on the probability integral transform and by applying scoring rules.</abstract>
            <doi>10.1002/jae.2556</doi>
            <url>https://onlinelibrary.wiley.com/doi/pdf/10.1002/jae.2556</url>
        </article>
    </entry>
    <entry id="RRBB17">
        <article>
            <author>Rueda-Cantuche, J. M. and Amores, A. F. and Beutel, J. and R\'emond-Tiedrez, I.</author>
            <title>Assessment of {E}uropean use tables at basic prices and valuation matrices in the absence of official data</title>
            <journal>#J_ESR#</journal>
            <year>2017</year>
            <volume>30</volume>
            <number>2</number>
            <pages>252-270</pages>
            <abstract>Input-Output modellers are often faced with the task of estimating missing Use tables at basic prices and also valuation matrices of the individual countries. This paper examines a selection of estimation methods applied to the European context where the analysts are not in possession of superior data. The estimation methods are restricted to the use of automated methods that would require more than just the row and column sums of the tables (as in projections) but less than a combination of various conflicting information (as in compilation). The results are assessed against the official Supply, Use and Input-Output tables of Belgium, Germany, Italy, Netherlands, Finland, Austria and Slovakia by using matrix difference metrics. The main conclusion is that using the structures of previous years usually performs better than any other approach.</abstract>
            <doi>10.1080/09535314.2017.1372370</doi>
            <url>https://www.tandfonline.com/doi/full/10.1080/09535314.2017.1372370</url>
        </article>
    </entry>
    <entry id="BBKKMMP16">
        <techreport>
            <author>Baldacci, E. and Buono, D. and Kapetanios, G. and Krische, S. and Marcellino, M. G. and Mazzi, G. L. and Papailias, F.</author>
            <title>Big data and macroeconomic nowcasting: {F}rom data access to modelling</title>
            <institution>#O_EC_ESTAT#</institution>
            <year>2016</year>
            <note>Statistical Books</note>
            <abstract>Parallel advances in IT and in the social use of Internet-related applications, provide the general public with access to a vast amount of information. The associated Big Data are potentially very useful for a variety of applications, ranging from marketing to tapering fiscal evasion.
From the point of view of official statistics, the main questions is whether and to what extent Big Data are a field worth investing to expand, check and improve the data production process and which types of partnerships will have to be formed for this purpose. Nowcasting of macroeconomic indicators represents a well-identified field where Big Data has the potential to play a decisive role in the future. In this paper we present the results and main recommendations from the Eurostat-funded project "Big Data and macroeconomic nowcasting", implemented by GOPA Consultants, which benefits from the cooperation and work of the Eurostat task force on Big Data and a few external academic experts.</abstract>
            <doi>10.2785/360587</doi>
            <url>https://ec.europa.eu/eurostat/documents/3888793/7753027/KS-TC-16-024-EN-N.pdf</url>
        </techreport>
    </entry>
    <entry id="Eiselt16">
        <incollection>
            <author>Eiselt, B.</author>
            <title>{LUCAS}-{E}rhebung: {B}oden\-bedeckung und {B}oden\-nutzung in der {EU}</title>
            <booktitle>Fl{\"a}chen\-nutzungs\-monitoring {VIII}. Fl{\"a}chen\-sparen \textendash{} {\"O}ko\-system\-leis\-tungen \textendash{} {H}andlungs\-strategien</booktitle>
            <year>2016</year>
            <editor>Meinel, G. and F{\"o}rtsch, D. and Schwarz, S. and Kr{\"u}ger, T.</editor>
            <url>http://slub.qucosa.de/api/qucosa\%3A16825/attachment/ATT-0/</url>
        </incollection>
    </entry>
    <entry id="FJTOPE16">
        <techreport>
            <author>Fern\'andez-Ugalde, O. and Jones, A. and T\'oth, G. and Orgiazzi, A. and Panagos, P. and Eiselt, B.</author>
            <title>{LUCAS} soil component: {P}roposal for analysing new physical, chemical and biological soil parameter</title>
            <institution>#O_EC_JRC#</institution>
            <year>2016</year>
            <abstract>While unemployment in the EU is above 10\%, the job vacancy rate also remains high around 1.5\%. This suggests considerable unmet demand for skills, which is in the focus of the EU employment promotion policies. This paper studies the special role that schooled ICT experts in firms - an intangible input often neglected and difficult to measure - play for productivity. The effects are investigated both in isolation and in conjunction with the impact of ICT maturity on microdata in six European countries (UK, France, Sweden, Norway, Denmark and Finland) for the period 2001-2009. We find that increases in the proportion of ICT-intensive human capital boosts productivity. This seems to confirm the case in favour of recruitment of highly skilled ICT employees. However, the gains vary across countries and industries, suggesting that the channels through which the effects operate are narrower for ICT-intensive human capital than for skilled human capital in general. Our findings provide an important message to the EU employment policy debate that currently revolves around the skill mismatch in general and the unmet demand for ICT skills in particular.</abstract>
            <doi>10.2788/884940</doi>
            <url>https://publications.jrc.ec.europa.eu/repository/bitstream/JRC102485/lb-na-28038-en-n%20.pdf</url>
        </techreport>
    </entry>
    <entry id="IMZKPRS16">
        <article>
            <author>Ioannidis, E. and Merkouris, T. and Zhang, L.-C. and Karlberg, M. and Petrakos, M. and Reis, F. and Stavropoulos, P.</author>
            <title>On a modular approach to the design of integrated social surveys</title>
            <journal>#J_JOS#</journal>
            <year>2016</year>
            <volume>32</volume>
            <number>2</number>
            <pages>259-286</pages>
            <abstract>This article considers a modular approach to the design of integrated social surveys. The approach consists of grouping variables into ‘modules’, each of which is then allocated to one or more ‘instruments’. Each instrument is then administered to a random sample of population units, and each sample unit responds to all modules of the instrument. This approach offers a way of designing a system of integrated social surveys that balances the need to limit the cost and the need to obtain sufficient information. The allocation of the modules to instruments draws on the methodology of split questionnaire designs. The composition of the instruments, that is, how the modules are allocated to instruments, and the corresponding sample sizes are obtained as a solution to an optimisation problem. This optimisation involves minimisation of respondent burden and data collection cost, while respecting certain design constraints usually encountered in practice. These constraints may include, for example, the level of precision required and dependencies between the variables. We propose using a random search algorithm to find approximate optimal solutions to this problem. The algorithm is proved to fulfil conditions that ensure convergence to the global optimum and can also produce an efficient design for a split questionnaire.</abstract>
            <doi>10.1515/jos-2016-0013</doi>
            <url>https://content.sciendo.com/view/journals/jos/32/2/article-p259.xml</url>
        </article>
    </entry>
    <entry id="LSJ16">
        <inproceedings>
            <author>Lazar, A. C. and Selenius, J. and Jortay, M.</author>
            <title>Strategy for agricultural statistics 2020 and beyond: for the future {E}uropean {A}gricultural {S}tatistics {S}ystem ({EASS}).</title>
            <booktitle>#C_ICAS#</booktitle>
            <year>2016</year>
            <abstract>Many important policies of the European Union, such as the Common Agricultural Policy, depend on agricultural statistics. These statistics need to be of high quality, coherent, comparable and flexible, and should be produced efficiently based on users' needs in order to best serve evidence-based policy making and monitoring. The current EU agricultural statistics system does not fulfil these requirements well enough. To address this, Eurostat launched the "New legislation on Agricultural Statistics for a strategy towards 2020 and beyond" initiative in 2014. It aims to introduce two new legal frameworks stepwise: an"Integrated Farm Statistics" Regulation which will provide the basis for collecting farm level micro-data, based on a modular approach with core, module and ad hoc surveys; and a "Statistics on Agricultural Input/Output" Regulation which will provide aggregated statistics in tabular form. These frameworks will contain basic elements such as scope, precision and quality requirements and will use common definitions and classifications, while more technical elements will be covered by secondary legislation. EU Member States will be free to choose data sources, including administrative and other new data sources. This paper presents the Strategy for agricultural statistics 2020 and beyond and shows its suitability to meet technical and methodological requirements as well as to successfully navigate the complex institutional, legal and political context within the European Union and its 28 Member States. It can therefore serve as an instructive example for a cross-border implementation of the United Nations Global Strategy to improve agricultural and rural Statistics.</abstract>
            <doi>10.1481/icasVII.2016.f37c</doi>
            <url>https://www.istat.it/storage/icas2016/f37-lazar.pdf</url>
        </inproceedings>
    </entry>
    <entry id="RAR16">
        <inproceedings>
            <author>R\'emond-Tiedrez, I. and Amores, A. F. and Rueda-Cantuche, J. M.</author>
            <title>Development of a quality adjusted labour productivity index in the {E}uropean {U}nion \textendash{} {E}xample of the employment embodied in {E}uropean exports</title>
            <booktitle>#C_IIOC#</booktitle>
            <year>2016</year>
            <abstract>The  paper will introduce the methodology for the Quality Adjusted Labour Index (QALI) in the European Union which combines macro-data from  National Accounts (which are the benchmarked data)  and micro-data from the EU statistics of the Labour Force survey (LFS) and the Structural Earnings Survey (SES). The Quality Adjusted Labour Input is constructed for the EU-28, EA-19 and each EU MS, whenever data are available, for the  full time series from 2002 to 2013, with possible extension to 2014. Survey-based data of hours worked and earnings for 2002-2007 are converted from NACE Rev.1.1to  NACE  Rev.2. The QALI values by EU Member State are weighted by skills,  by age and by combinations of skill and age groups. The industry breakdown varies depending on countries due to reliability/confidentiality constraints of the survey data: 21 industries (A21) for some countries, EU28 and EA19; 10 industries (A10); and the total economy. Connected to the decomposition of the volume by type of workers (by age and by skill), the results will give interesting insights on what kind of employment is supported by European exports in terms of age, qualifications,  and in which industrial activities. The results will be based on the European consolidated Supply, Use and Input-Output Tables produced annually by Eurostat.</abstract>
            <url>https://www.iioa.org/conferences/24th/papers/files/2341.pdf</url>
        </inproceedings>
    </entry>
    <entry id="AGKRV15">
        <article>
            <author>Agafitei, M. and Gras, F. and Kloek, W. and Reis, F. and V\^aju, S. C.</author>
            <title>Measuring output quality for multisource statistics in official statistics: {S}ome directions</title>
            <journal>#J_SJIAOS#</journal>
            <year>2015</year>
            <volume>31</volume>
            <number>2</number>
            <pages>203-211</pages>
            <abstract>Many statistical offices have been moving towards an increased use of administrative data sources for statistical purposes, both as a substitute and as a complement to survey data. Moreover, the emergence of big data constitutes a further increase in available sources. As a result, statistical output in official statistics is increasingly based on complex combinations of sources.The quality of such statistics depends on the quality of the primary sources and on the ways they are combined.This paper analyses the appropriateness of the current set of output quality measures for multiple source statistics, it explains the need for improvement and outlines directions for further work. The usual approach for measuring the quality of the statistical output is to assess quality through the measurement of the input and process quality. The paper argues that in multisource production environment this approach is not sufficient. It advocates measuring quality on the basis of the output itself - without analysing the details of the inputs and the production process - and proposes directions for further development.</abstract>
            <doi>10.3233/sji-150902</doi>
            <url>https://content.iospress.com/download/statistical-journal-of-the-iaos/sji902?id=statistical-journal-of-the-iaos\%2Fsji902</url>
        </article>
    </entry>
    <entry id="BLL15">
        <article>
            <author>Bautier, P. and Laevaert, C. and Le Goff, B.</author>
            <title>Tracking users for a targeted dissemination</title>
            <journal>#J_Statistika#</journal>
            <year>2015</year>
            <volume>95</volume>
            <number>4</number>
            <pages>77-78</pages>
            <abstract>How to build a dissemination and communication strategy in a world where users have easy access to a deluge of data and information from various origins and where IT tools and design standards change so quickly that users behaviour and their expectations are continuously modified? The first challenge of Eurostat is clearly to know what users want: we know our different types of users but we have to identify how they get our data, what they do with our data, how they react to our outputs and which sort of new service they would like us to propose. Translating these needs into a visual dissemination is a new challenge undertaken by Eurostat through a new portal, new mobile apps and new info graphs and basic application as well as increasing the visibility on Google. The objective of this paper is to share Eurostat's experience in identifying user needs and to show how concretely this information has been visually disseminated.</abstract>
            <url>https://www.czso.cz/documents/10180/20550319/32019715q4067.pdf</url>
        </article>
    </entry>
    <entry id="BBBEKLMR15">
        <manual>
            <author>Boxall, M. and Brown, G. and Buono, D. and Elliott, D. and Kirchner, R. and Ladiray, D. and Mazzi, G. L. and Ruggeri Cannata, R.</author>
            <title>{ESS} guidelines on seasonal adjustment</title>
            <year>2015</year>
            <abstract>The establishment of common guidelines for seasonal adjustment (SA) within the European Statistical System (ESS) is an essential step towards a better harmonisation and comparability of infra-annual statistics, especially Principal European Economic Indicators (PEEIs).
The ESS Guidelines on Seasonal Adjustment address the need for harmonisation expressed on several occasions by many users such as the European Central Bank (ECB), European Commission services, and the ECOFIN Council. The definition of best practices in the field of seasonal adjustment has been long debated at European level. Since 2007, the Seasonal Adjustment Steering Group co-chaired by Eurostat and the ECB gave a new and crucial input to the compilation of the first edition of the guidelines, published in 2009. The first edition has been widely accepted and implemented. However, taking into account the experience accumulated since 2009 and the need to further clarify some specific aspects, in 2012 the Seasonal Adjustment Steering Group decided to launch a revision of the guidelines. The ESS Guidelines on Seasonal Adjustment are the outcome of the revision work and the ESS Committee (ESSC) endorsed them in November 2014. The revised ESS Guidelines on Seasonal Adjustment present both theoretical aspects and practical implementation issues in a friendly and easy to read framework, thereby addressing both experts and non- experts in seasonal adjustment. They meet the requirement of principle 7 (Sound Methodology) of the European Statistics Code of Practice and their implementation will also be in line with principles 14 (Coherence and Comparability) and 15 (Accessibility and Clarity). The guidelines also foster the transparency of seasonal adjustment practices by encouraging the documentation of all seasonal adjustment steps and the dissemination of seasonal adjustment practices by means of the metadata template for seasonal adjustment. Finally they allow for development of expertise and capacity building. The revised version of the guidelines includes a new section with a policy for seasonal adjustment, making the revised version of the guidelines consistent with the guidelines on revisions policies. It also better describes the different steps in seasonal adjustment. Finally the specification of alternatives has been reviewed, making them more operational.</abstract>
            <doi>10.2785/317290</doi>
            <url>https://ec.europa.eu/eurostat/documents/3859598/6830795/KS-GQ-15-001-EN-N.pdf</url>
        </manual>
    </entry>
    <entry id="Gotfried15">
        <incollection>
            <author>G{\"o}tzfried, A.</author>
            <title>Modernising {O}fficial {S}tatistics: {A} complex challenge</title>
            <booktitle>Data Science, Learning by Latent Structures, and Knowledge Discovery</booktitle>
            <publisher>#P_S#</publisher>
            <year>2015</year>
            <editor>Lausen, B. and Krolak-Schwerdt, S. and B{\"o}hmer, M.</editor>
            <series>#S_SCDAKO#</series>
            <pages>3-11</pages>
            <abstract>In Europe, national statistical organisations and Eurostat, the statistical office of the European Union, produce and disseminate official statistics. These organisations come together as partners in the European Statistical System (ESS). This paper describes the ESS, the challenges it faces and the modernisation efforts that have been undertaken based on a redesigned ESS enterprise architecture. It also outlines the probable future direction of the ESS.</abstract>
            <doi>10.1007/978-3-662-44983-7_1</doi>
            <url>https://link.springer.com/chapter/10.1007%2F978-3-662-44983-7_1</url>
        </incollection>
    </entry>
    <entry id="HZFP16">
        <article>
            <author>Haldorson, M. and Zaccheddu, P.-G. and Fohgrub, B. and Petri, E.</author>
            <title>Geospatial information management in {E}urope \textendash{} {R}esponding to the user needs</title>
            <journal>#J_SJIAOS#</journal>
            <year>2016</year>
            <volume>32</volume>
            <number>4</number>
            <pages>481-487</pages>
            <abstract>The United Nations initiative on Global Geospatial Information Management (UN-GGIM) aims at playing a leading role in setting the agenda for the development of global geospatial information and to promote its use to address key global challenges like the UN Sustainable Development Goals. The regional committee UN-GGIM: Europe was established in October 2014 and by October 2015, at its second plenary meeting, recommendations were adopted on better integration of geospatial and statistical information in order to foster further usage. The recommendations can be found in a report titled ''Definition of the priority user needs for combinations of data''. This article reflects the main content of the report: identifying relevant policies, collecting use cases, describing and responding to user needs and finally making recommendations on how to improve the integration of statistical and geospatial information. The most strategic recommendation is that Europe should aim for a European Spatial Data Strategy. Other recommendations deal with priority data for a Statistical Geospatial Framework and support the improvement of workflows with geospatial technology.</abstract>
            <doi>10.3233/SJI-161010</doi>
            <url>https://content.iospress.com/download/statistical-journal-of-the-iaos/sji1010?id=statistical-journal-of-the-iaos%2Fsji1010</url>
        </article>
    </entry>
    <entry id="IBB15">
        <article>
            <author>Infante, E. and Buono, D. and Buono, A.</author>
            <title>A 3-way {ANOVA} a priori test for common seasonal patterns and its application to direct versus indirect methods</title>
            <journal>#J_EURONA#</journal>
            <year>2015</year>
            <volume>1</volume>
            <pages>93-145</pages>
            <abstract>In this paper we propose a new a priori test to be used for the identification of a common seasonal pattern. The test is applied a priori to any running of a seasonal adjustment procedure. The test is a three way ANOVA, where the three factors are the series, the time frequency and the year. One of the possible applications of using such a test would be when selecting either the direct or indirect approach when seasonally adjusting. The Seasonally Adjusted series of an aggregate can be obtained by seasonal adjusting it (direct approach) or by aggregating the seasonally adjusted individual series (indirect approach). It should be noted that, to date, the literature has been mainly focusing on an a posteriori comparison among the results achieved by applying different approaches. This paper seeks to set out an a priori strategy for the identification of the most effective seasonal adjustment of the aggregate.</abstract>
            <issn>1977-978X</issn>
            <url>https://ec.europa.eu/eurostat/cros/system/files/05y-newanova_techsav_dtp_final.pdf</url>
        </article>
    </entry>
    <entry id="Karlberg16">
        <article>
            <author>Karlberg, M.</author>
            <title>Reviewers should ask the right questions \textendash{} {B}ut is {I}nfo{Q} the answer?</title>
            <journal>#J_SJIAOS#</journal>
            <year>2016</year>
            <volume>32</volume>
            <number>1</number>
            <pages>29-31</pages>
            <abstract>Kenett and Shmueli rightly note that statisticians in academia, industry (and the public sector for that matter!) are regularly reviewing papers for journals without a general framework to help them guide the review process, meaning that "it is typically left to the reviewer's experience and good sense to determine the contribution of a paper". The inevitable consequence is indeed that the review process "is usually carriedout in an unstructured way with inherent variability between reviewers".To remedy this regrettable state of affairs, the authors propose that a set of items based on the InfoQ framework be adopted in the reviewing process of applied journals. This discussion paper which reflects on their proposal, starts by identifying possible actions complementary to a reviewing framework in Section 2. Thereafter, the applicability of the proposed framework is discussed in Section 3, while Section 4 contains some concluding remarks.</abstract>
            <doi>10.3233/SJI-160980</doi>
            <url>https://content.iospress.com/download/statistical-journal-of-the-iaos/sji980?id=statistical-journal-of-the-iaos%2Fsji980</url>
        </article>
    </entry>
    <entry id="KRCG15">
        <article>
            <author>Karlberg, M. and Reis, F. and Calizzani, C. and Gras, F.</author>
            <title>A toolbox for a modular design and pooled analysis of sample survey programmes</title>
            <journal>#J_SJIAOS#</journal>
            <year>2015</year>
            <volume>31</volume>
            <number>3</number>
            <pages>447-462</pages>
            <abstract>This paper presents key methodological results from a project on streamlining and integrating sample survey programmes. More specifically, it: Proposes a general modular framework and integrated survey systems (in concrete terms, i.e. with a specific set of surveys as the point of departure); Presents a toolbox (covering estimation, sample allocation and instrument composition) to deal with the methodological challenges associated with such integrated systems; and Indicates possible steps to upgrade statistical production systems from a collection of uncoordinated surveys to a harmonised integrated system of surveys. A concrete application of the 'instrument composition' part of the toolbox demonstrates how the EU Labour Force Survey, the EU Survey on Income and Living Conditions and the EU Adult Education Survey could be combined so as to improve flexibility (responding to new user needs), efficiency (greater precision or reduced costs) and transversality (capacity to combine variables from different statistical domains).</abstract>
            <doi>10.3233/SJI-150913</doi>
            <url>https://content.iospress.com/download/statistical-journal-of-the-iaos/sji913?id=statistical-journal-of-the-iaos%2Fsji913</url>
        </article>
    </entry>
    <entry id="CP01">
        <article>
            <author>Caridi, P. and Passerini, P.</author>
            <title>The underground economy, the demand for currency approach and the analysis of discrepancies: {S}ome recent {E}uropean experience</title>
            <journal>#J_RIW#</journal>
            <year>2001</year>
            <volume>47</volume>
            <number>2</number>
            <pages>239-250</pages>
            <abstract>Recent estimates of the size of the "underground economy" have used the so-called "demand for currency approach." One of the assumptions made by these studies is that official statistics do not take into account the underground economy when estimating GDP. After setting some definitions, the paper presents a brief critical review of the method and results obtained for the European Union using this approach. It points out that the different concepts of unreported and unrecorded activities are incorrectly considered to be equivalent. The third section, after a review of the method of estimating the underground economy using the discrepancy approach, presents the new results of the authors which give an indication of the amount of the unreported activities already included in official national accounts statistics in the EU. The results of the discrepancy approach disprove the widespread belief that official statistics only include officially recorded transactions and reinforce the critical view on the results obtained with the currency-demand approach.</abstract>
            <doi>10.1111/1475-4991.00014</doi>
            <url>https://onlinelibrary.wiley.com/doi/epdf/10.1111/1475-4991.00014</url>
        </article>
    </entry>
    <entry id="RBB15">
        <article>
            <author>Ruggeri Cannata, R. and Buono, D. and Biscosi, F.</author>
            <title>The {M}acroeconomic {I}mbalances {P}rocedure and the scoreboard: {E}nsuring data coverage</title>
            <journal>#J_EURONA#</journal>
            <year>2015</year>
            <volume>2</volume>
            <pages>97-118</pages>
            <abstract>The Macroeconomic Imbalance Procedure (MIP) is a surveillance mechanism that aims to identify potential risks early on, prevent the emergence of harmful macroeconomic imbalances and correct the imbalances that are already in place. It is a system for monitoring economic policies and detecting potential harms to the proper functioning of the economy of a Member State, of the Economic and Monetary Union, and of the European Union as a whole. The MIP is supported by the analysis of a set of headline and auxiliary indicators, whose data coverage can reach twenty years due to data transformations. In order to ensure the necessary time series length for policy makers, statisticians can resort to statistical techniques such as back-calculation. This paper illustrates the MIP in the European Union policy context and some applications of back-calculation to two MIP indicators.</abstract>
            <issn>1977-978X</issn>
            <url>https://ec.europa.eu/eurostat/documents/3217494/7114363/KS-GP-15-002-EN-N.pdf</url>
        </article>
    </entry>
    <entry id="Wirthmann16">
        <article>
            <author>Wirthmann, A.</author>
            <title>Big data im {E}urop{\"a}ischen {S}tatistischen {S}ystem \textendash{} {B}eitrag zur {R}eaktion des {E}urop{\"a}ischen {S}tatistischen {S}ystem auf die big data-{H}erausforderung</title>
            <journal>#J_AWSA#</journal>
            <year>2016</year>
            <volume>10</volume>
            <pages>151-161</pages>
            <abstract>Starting with the Scheveningen Memorandum, Eurostat created an internal Task Force “Big Data” that is coordinating the activities of the European Statistical System (ESS) on Big Data. The activities are based on the Big Data Action Plan and Roadmap which was endorsed by the European Statistical System Committee in June 2014. The Action Plan identifies short, medium and long term objectives aiming at integrating big data sources into the production of European Statistics. The BIGD project makes part of the ESS Vision 2020 for modernising European Statistics. Pilots that investigate the potential of selected big data sources for European Statistics constitute the core part of the BIGD project. The pilots are conducted by a consortium of national statistical institutes, so called ESSnets, which are co-financed by the European Commission. The pilots are backed by a number of cross-cutting activities that analyse conditions of using big data by statistical institutes, such as analysis of the legal situation, ethical principles, skills and competences, and communication. The ESSnet started working in 2016, activities will terminate in 2019. The long term objective of the Big Data Action Plan and Roadmap is integrating big data into the portfolio of European Statistics. The ESS is closely collaborating with initiatives at UN level and with data for policy initiatives at the European Commission.</abstract>
            <doi>10.1007/s11943-016-0195-z</doi>
            <url>https://link.springer.com/content/pdf/10.1007%2Fs11943-016-0195-z.pdf</url>
        </article>
    </entry>
    <entry id="CS14">
        <incollection>
            <author>Chiappero-Martinetti, E. and Sabadash, A.</author>
            <title>Integrating human capital and human capabilities in understanding the value of education</title>
            <booktitle>The Capability Approach: From Theory to Practice</booktitle>
            <publisher>#P_PM#</publisher>
            <year>2014</year>
            <editor>Ibrahim, S. and Tiwari, M.</editor>
            <pages>206-230</pages>
            <address>#A_Lond#</address>
            <note>MPRA Paper 61800</note>
            <abstract>The aim of this chapter is to investigate the possibility of combining human capital theory (HCT) and the capability approach (CA) in order to better understand and measure both the instrumental and the intrinsic values of education for individuals, and to trace its relative spillover effects on societies. HCT, pioneered by Schultz and Becker in the early 1970s, has since become an important part of the debate on economic growth and development. Recently, HCT has been criticised for the narrow instrumental role that it assigns to education (inasmuch as HCT disregards some of important non-material aspects of education), as well as for its inability to satisfactorily reflect the cultural, gender-based, emotional and historical differences that can influence educational choices and individual well-being.</abstract>
            <doi>10.1057/9781137001436_9</doi>
            <url>https://link.springer.com/content/pdf/10.1057%2F9781137001436.pdf</url>
        </incollection>
    </entry>
    <entry id="HS14">
        <techreport>
            <author>Hagsten, E. and Sabadash, A.</author>
            <title>The impact of highly-skilled {ICT} labour on firm performance: {E}mpirical evidence from six {E}uropean countries</title>
            <institution>#O_EC_JRC#</institution>
            <year>2014</year>
            <note>Working Papers on Digital Economy 2014-02</note>
            <abstract>While unemployment in the EU is above 10\%, the job vacancy rate also remains high around 1.5\%. This suggests considerable unmet demand for skills, which is in the focus of the EU employment promotion policies. This paper studies the special role that schooled ICT experts in firms - an intangible input often neglected and difficult to measure - play for productivity. The effects are investigated both in isolation and in conjunction with the impact of ICT maturity on microdata in six European countries (UK, France, Sweden, Norway, Denmark and Finland) for the period 2001-2009. We find that increases in the proportion of ICT-intensive human capital boosts productivity. This seems to confirm the case in favour of recruitment of highly skilled ICT employees. However, the gains vary across countries and industries, suggesting that the channels through which the effects operate are narrower for ICT-intensive human capital than for skilled human capital in general. Our findings provide an important message to the EU employment policy debate that currently revolves around the skill mismatch in general and the unmet demand for ICT skills in particular.</abstract>
            <url>https://ec.europa.eu/jrc/sites/jrcsh/files/ReqNo_JRC89703_The%20Impact%20of%20Highly-skilled%20ICT%20Labour%20on%20Firm%20Performance%20Empirical%20Evidence%20from%20Six%20Countries.pdf</url>
        </techreport>
    </entry>
    <entry id="PBS14">
        <techreport>
            <author>Pantea, S. and Biagi, F. and Sabadash, A.</author>
            <title>Are {ICT} displacing workers? {E}vidence from seven {E}uropean countries</title>
            <institution>#O_EC_JRC#</institution>
            <year>2014</year>
            <abstract>This paper examines whether ICT substitute labour and reduce the demand for labour. We used firm-level comparable data separately for firms in manufacturing, services and ICT-producing sectors from seven European countries. We adopted a common methodology and applied it to a unique dataset provided by the ESSLait Project on Linking Microdata. We controlled for unobservable time-invariant firm-specific effects and we found no evidence of a negative relationship between intensity of ICT use and employment growth. We read this as an indication that ICT use is not reducing employment among ICT using firms.</abstract>
            <url>https://ec.europa.eu/jrc/sites/jrcsh/files/JRC91122_ICT_displacing_workers.pdf</url>
        </techreport>
    </entry>
    <entry id="Sabadash14">
        <techreport>
            <author>Sabadash, A.</author>
            <title>Employment of {ICT} specialists in the {EU} (2000-2012)</title>
            <institution>#O_EC_JRC#</institution>
            <year>2014</year>
            <note>Working Papers on Digital Economy 2014-01, MPRA Paper 61644</note>
            <abstract>This study examines the evolution of the number of ICT-skilled workers employed in industry sectors in the EU28  over  the  period  2000-2012. Data are taken from the Eurostat Labour Force Statistics. It introduces a novel definition of ICT specialists that combines occupations and skills taxonomies. For the period prior to the introduction of the Standard Classification of Occupations (ISCO-08) it starts from the OECD definition but includes a wider range of ICT  occupations. From  2011 onwards it adopts the thematic view for ICT occupations proposed by the ILO (2012). It confirms that employment of  ICT specialists  in  the EU27 has  been  resilient  to  the  economic downturn and  uncertainty in global  labour markets, and was able to maintain a growth path of 4.3\% per year over the period  2000-2012,  more than 7 times higher than average growth of total employment over the same period. Though ICT employment evolved cyclically it never turned negative. This rapid growth in ICT employment confirms the increasing importance of ICT technologies in the global economy.</abstract>
            <url>https://ec.europa.eu/jrc/sites/jrcsh/files/JRC92503_Employment_of_ICT_Specialists.pdf</url>
        </techreport>
    </entry>
    <entry id="DM13">
        <article>
            <author>Defays, D. and Museux, J.-M.</author>
            <title>Discussion</title>
            <journal>#J_JOS#</journal>
            <year>2013</year>
            <volume>29</volume>
            <number>1</number>
            <pages>147-155</pages>
            <abstract>This discussion draws mainly on four contributions in this special issue (those of Statistics New Zealand, NASS, RTI International and Statistics Netherlands) that report on experiences in integrating statistical production systems with a direct focus on industrialisation and integration-related issues. The framework proposed by Eltinge et al. for the integration of architecture and methodology is also taken on board. The article on the Real-Time Online Analytic System (Westat/NCHS) is marginally integrated into the discussion on data access.</abstract>
            <doi>10.2478/jos-2013-0008</doi>
            <url>https://content.sciendo.com/view/journals/jos/29/1/article-p147.xml</url>
        </article>
    </entry>
    <entry id="IB13">
        <inproceedings>
            <author>Infante, E. and Buono, D.</author>
            <title>New technique for predictability, uncertainty, implied volatility and statistical analysis of market risk using {SARIMA} forecasts intervals</title>
            <booktitle>#C_NTTS#</booktitle>
            <year>2013</year>
            <abstract>Market price data plays an essential role when aiming at the production of quality statistics to be used by policy makers at EU level. Market risk can be defined as the risk of losses in positions arising from movements in market prices, generally linked to the risk that commodity prices and/or their implied volatility will change. From the analyst's perspective, the most informative data are possibly located within the end-series observations. This paper proposes a new Technique for Statistics to be used for assessing the presence of commodity risk that might cause market risk. The underlining idea is to assess whether the realized prices for a determined product in a specified time span is significantly apart from the SARIMA forecasts intervals. Such procedure aims also at identifying the type of eventual outliers present within the end-series observations. An applied case study on agricultural price statistics in Italy is here presented.</abstract>
            <url>https://ec.europa.eu/eurostat/cros/system/files/NTTS2013fullPaper_143.pdf</url>
        </inproceedings>
    </entry>
    <entry id="IBB13">
        <inproceedings>
            <author>Infante, E. and Buono, D. and Buono, A.</author>
            <title>{IB} test for direct versus indirect approach in seasonal adjustment</title>
            <booktitle>#C_NTTS#</booktitle>
            <year>2013</year>
            <abstract>The seasonally adjusted series of an aggregate can be obtained by seasonal adjusting it ("direct approach") or by aggregating the seasonally adjusted individual series ("indirect approach"). The literature to date has mainly focused upon an a posteriori comparison among the results achieved by applying different approaches. Here a new a priori test (IB test) for choosing between direct and indirect approach in seasonal adjustment is proposed. The test is applied before running any seasonal adjustment procedure. When the individual series present common seasonal patterns the aggregate will be adjusted directly, otherwise an indirect approach could be preferred. Sections 3 and 4 include a simulation and a case study, respectively. This paper seeks to set out an a priori strategy for the identification of the most effective seasonal adjustment approach to be used.</abstract>
            <url>https://ec.europa.eu/eurostat/cros/system/files/NTTS2013fullPaper_143.pdf</url>
        </inproceedings>
    </entry>
    <entry id="RM10">
        <inproceedings>
            <author>Reuter, W.H. and Museux, J.-M.</author>
            <title>Establishing an infrastructure for remote access to microdata at {E}urostat</title>
            <booktitle>#C_ICPSD#</booktitle>
            <year>2010</year>
            <editor>Domingo-Ferrer, J. and Magkos, E.</editor>
            <volume>6344</volume>
            <series>#S_LNCS#</series>
            <pages>249-257</pages>
            <address>#A_H#</address>
            <publisher>#P_S#</publisher>
            <abstract>Eurostat is pursuing the establishment of an infrastructure for remote access for researchers in order to satisfy the growing demand for microdata. Some European countries already implemented such solutions. This paper compares the systems which can be categorized in (1) terminal server, (2) distance network and (3) job submission systems. They differ in IT infrastructure, workstation control, user management and authentication, file systems and disclosure control activities. The second part of the paper describes the efforts and outlook as well as options and challenges for Eurostat when building such a system.</abstract>
            <doi>10.1007/978-3-642-15838-4_22</doi>
            <url>https://link.springer.com/chapter/10.1007%2F978-3-642-15838-4_22</url>
        </inproceedings>
    </entry>
    <entry id="BM09">
        <article>
            <author>Bujnowska, A. and Museux, J.-M.</author>
            <title>Release of {E}uropean {U}nion microdata, {ESS} projects on remote access</title>
            <journal>#J_SJIAOS#</journal>
            <year>2009</year>
            <volume>26</volume>
            <pages>89-94</pages>
            <abstract>This paper outlines microdata access methods at the European level, and specifically to data governed by European Union (EU) Regulation 831/2002 or where explicit approval of the EU Members is given on the access to particular datasets via Eurostat safe centre. Access to EU microdata for research purposes was enabled in 2002 when the Commission Regulation (EC) No 831/2002 came into force. Since then more than 100 contracts have been signed each year with research organisations for the provision of microdata for scientific purposes. The current Regulation foresees two ways of access to microdata: access to anonymised microdata files, and access to confidential data in the safe centre in Eurostat premises in Luxembourg. The first part of the paper outlines the legal framework at the EU level. The second part discusses the different modes and conditions of access as well as practical issues related to access to microdata in general. The final part provides an overview of the projects currently carried out in the domain of remote access at the European level. The situation with regards to the access to EU microdata will evolve in the near future with the new regulatory framework and subsequent changes in the governance structure for statistical confidentiality in the European Statistical System.</abstract>
            <doi>10.3233/SJI-2009-0709</doi>
            <url>https://content.iospress.com/download/statistical-journal-of-the-iaos/sji00709?id=statistical-journal-of-the-iaos%2Fsji00709</url>
        </article>
    </entry>
    <entry id="MPJ08">
        <inproceedings>
            <author>Museux, J.-M. and Peeters, M. and Jo\~{a}o Santos, M.</author>
            <title>Legal, political and methodological issues in confidentiality in the {E}uropean {S}tatistical {S}ystem</title>
            <booktitle>#C_ICPSD#</booktitle>
            <year>2008</year>
            <editor>Domingo-Ferrer, J. and Saygın, Y.</editor>
            <volume>5262</volume>
            <series>#S_LNCS#</series>
            <pages>324-334</pages>
            <address>#A_H#</address>
            <publisher>#P_S#</publisher>
            <abstract>The paper discusses the challenges linked to the need of the research community to have access to microdata files for scientific purposes. These needs have to be adequately balanced with the legal requirement of preserving the confidentiality of respondents. The paper presents the policies and instruments available at the European Union to progress in the supply of data to the research community, while respecting the legal requirements. More specifically, the paper explains the current process dealing with research projects and the work of the European Statistical System Network (ESSnet) project for statistical disclosure control. Finally the paper describes future trends that are currently investigated in the European Union, and more specifically the development of remote access facilities, the enhancement of disclosure control tools and the convergence towards common policies in Member States.</abstract>
            <doi>10.1007/978-3-540-87471-3_27</doi>
            <url>https://link.springer.com/chapter/10.1007/978-3-540-87471-3_27</url>
        </inproceedings>
    </entry>
    <entry id="GAF18">
        <inproceedings>
            <author>Gaffuri, J.</author>
            <title>Improving the quality of {O}fficial {S}tatistics with geographical disaggregation and dasymetric mapping: {T}wo {E}urostat experiments on tourism and population statistics</title>
            <booktitle>#C_Quality#</booktitle>
            <year>2018</year>
            <abstract>Official statistics are often reported on statistical units, which are sometimes too large to depict properly the geographical distribution of the underlying phenomenon. In the European context for example, most statistics are produced only at national level (NUTS 0) and do not allow a true understanding of the spatial pattern at more local scales. Geographic resolution is a crucial component of quality in official statistics which should be better addressed. This article describes two experiments carried out at Eurostat for disaggregating statistics with auxiliary geographic data. These experiments are both based on dasymetric mapping: Input statistical values are distributed at the level of geographical features; these new statistical values are then re-aggregated at the level of target statistical units with a finer resolution. A first experiment was the disaggregation of tourism statistics over Europe from NUTS 2 to NUTS 3 and a 10km resolution grid. The auxiliary geographic information used is a database containing the location of around 160000 touristic accomodations over Europe. The outcome reveals a striking image of touristic activity over Europe, with spatial patterns which cannot be revealed at NUTS 2 level. The second experiment was on the disaggregation of mobile phone data over Belgium to assess population distribution on a 1km resolution grid. Mobile phone data are collected at antenna level, whose reception zones are extremely irregular in shape and size, especially in rural areas. Cadastral information on the location and volume of each single building over Belgium has been used to locate more precisely mobile phone users around built-up areas. Both experiments show the pertinence of using geographic information with dasymetric mapping method to improve quality related to geographical resolution. This method has been implemented in the generic library JGiscoTools (https://github.com/eurostat/JGiscoTools) and is intended be applied to other domains.</abstract>
            <url>https://www.researchgate.net/publication/338609457_Improving_the_quality_of_official_statistics_with_geographical_disaggregation_based_on_dasymetric_mapping_Two_Eurostat_experiments_on_tourism_and_population_statistics</url>
        </inproceedings>
    </entry>
    <entry id="GAF18_2">
        <inproceedings>
            <author>Gaffuri, J.</author>
            <title>Generalising {O}pen{R}ailway{M}ap to 1:10k and 1:50k</title>
            <booktitle>#W_ICACGMR#</booktitle>
            <year>2018</year>
            <url>https://kartographie.geo.tu-dresden.de/downloads/ica-gen/workshop2018/ICA_Workshop_2018_railway_gaffuri.pdf</url>
        </inproceedings>
    </entry>
    <entry id="DKWR19">
        <article>
            <author>Descy, P. and Kvetan, V. and Wirthmann, A. and Reis, F.</author>
            <title>Towards a shared infrastructure for online job advertisement data</title>
            <journal>#J_SJIAOS#</journal>
            <year>2019</year>
            <volume>35</volume>
            <number>4</number>
            <pages>669-675</pages>
            <abstract>Following the increasing penetration of the internet, the number of websites that advertise jobs is growing. The European Centre for the Development of Vocational Training (Cedefop) and the ESSnet Big Data have engaged in parallel projects to assess the feasibility of using online job advertisements (OJA) for labour market analysis and job vacancy statistics. After an initial feasibility study finalised in 2016, Cedefop is developing a Pan-EU system providing information on skills demand present in OJA, which will be operational by 2020. The ESSnet has focussed on statistics that can be derived from OJA and entered into a second phase in November 2018 aiming at creating the conditions for a larger scale implementation of the use of OJA in official statistics. This paper builds on experiences gathered in both projects and identifies opportunities and limitations of using OJA for the above-mentioned purposes. In addition, it discusses the feasibility of creating a joint system for processing and analysing OJA data based on discussions that have taken place in the past two years between Cedefop and the ESSnet Big Data on both projects. In this respect, this paper outlines a possible partnership between Cedefop and the European Statistical System to create and manage a unique source of OJA data that would serve multiple uses in the domain of labour market analysis and official statistics. It presents potential types of (statistical) data and variables based on the information contained in OJAs at European, national and regional levels. Data limitations linked to OJAs nature and specificities will be stressed, too. The paper concludes that there is high potential for combining institutional efforts and creating a joint data collection and processing system on OJA and intends to feed a discussion on the feasibility and the implications of creating a European system for OJA, which can serve European and national needs.</abstract>
            <doi>10.3233/SJI-190547</doi>
            <url>https://content.iospress.com/articles/statistical-journal-of-the-iaos/sji190547</url>
        </article>
    </entry>
    <entry id="MABBCCDDKMNNVW12">
        <article>
            <author>Madans, J. and Abou-Zahr, C. and Bercovich, A. and Boerma, T. and Carlton, D. and Castro, L. and Desmedt, M. and Domingo, E. and Kahimbaara, J. and Marquardt, M. and Nviiri, H. and Norgaard, E. and Vassenden, E. and Wolfson, M.</author>
            <title>Reshaping health statistics: {A} new framework</title>
            <journal>#J_SJIAOS#</journal>
            <year>2012</year>
            <volume>28</volume>
            <pages>3-11</pages>
            <abstract>The field of health statistics has lagged behind other areas of statistics particularly in relation to reliable, timely, core information on health for use within countries and for cross national comparisons. A new framework is needed to successfully reshape health statistics. The UN Statistical Commission at its 35th meeting (2004) called for the establishment of an "inter-secretariat working group on health statistics (ISWG-HS) to develop a coordinated and integrated agenda for the production of health statistics and agree on standard definitions, classifications and methodologies in health statistics taking advantage of existing mechanisms wherever possible, and involving the community of official statistics at all stages." The Framework for health statistics described in this paper was developed by the members of this group. The Framework for Health Statistics provides a structure for identifying the kinds of information that should be collected; for assessing the extent to which these data are available and with what quality and comparability; for identifying data gaps; and for identifying where international standards are needed to support the collection of high-quality information. It facilitates dialogue among the national statistical authorities and other parties that fund or conduct health data collection, including health ministries and other para-statistical organizations such as institutes for public health.</abstract>
            <doi>10.3233/SJI-2012-0748</doi>
            <url>https://content.iospress.com/articles/statistical-journal-of-the-iaos/sji00748</url>
        </article>
    </entry>
    <entry id="DiazMunoz08">
        <article>
            <author>D\'iaz Mu\~{u}noz, P.</author>
            <title>The role of {S}tatistical {D}ata and {M}etadata e{X}change in global statistical infrastructure</title>
            <journal>#J_SJIAOS#</journal>
            <year>2008</year>
            <volume>25</volume>
            <pages>47-54</pages>
            <abstract>The attention given by statistical organisations to Statistical Data and Metadata Exchange (SDMX) is currently at unprecedented levels. This paper analyses the reasons for this and describes the key elements of this infrastructure. Furthermore, it describes all the dimensions of the SDMX initiative, namely, the standards, the exchange of data in different modes and the opportunity for the sharing of tools; and it links all these dimensions to the corresponding infrastructure elements. The paper also summarises the governance aspects of the initiative and outlines the benefits of adopting SDMX in an organisation, including the use of the data model in the statistical productions chain and to profit from the available components. Finally, a reflection on the global implementation of SDMX, as recommended by the United Nations Statistical Commission in February 2008, is provided in this paper. Finally, the paper urges national and international statistical organisations in the world to implement SDMX standards and guidelines and to use them in their exchanges of data; to participate in the governance mechanisms; and to act as a relay for promoting the use of SDMX by other partners. </abstract>
        </article>
    </entry>
    <entry id="FMMP10">
        <article>
            <author>Frale, C. and Marcellino, M. and Mazzi, G. L. and Proietti, T.</author>
            <title>Survey data as coincident or leading indicators</title>
            <journal>#J_JF#</journal>
            <year>2010</year>
            <volume>29</volume>
            <pages>109-131</pages>
            <abstract>In this paper we propose a monthly measure for the euro area gross domestic product (GDP) based on a small-scale factor model for mixed-frequency data, featuring two factors: the first is driven by hard data, whereas the second captures the contribution of survey variables as coincident indicators. Within this framework we evaluate both the in-sample contribution of the second survey-based factor, and the short-term forecasting performance of the model in a pseudo-real-time experiment. We find that the survey-based factor plays a significant role for two components of GDP: industrial value added and exports. Moreover, the two-factor model outperforms in terms of out-of-sample forecasting accuracy the traditional autoregressive distributed lags (ADL) specifications and the single-factor model, with few exceptions.
</abstract>
            <doi>10.1002/for.1142</doi>
            <url>https://onlinelibrary.wiley.com/doi/epdf/10.1002/for.1142</url>
        </article>
    </entry>
    <entry id="BFGM13">
        <article>
            <author>Billio, M. and Ferrara, L. and Gu\'egan, D. and Mazzi, G. L.</author>
            <title>Evaluation of regime switching models for real-time business cycle analysis of the {E}uro area</title>
            <journal>#J_JF#</journal>
            <year>2013</year>
            <volume>32</volume>
            <number>7</number>
            <pages>577-586</pages>
            <abstract>In this paper, we aim at assessing Markov switching and threshold models in their ability to identify turning points of economic cycles. By using vintage data updated on a monthly basis, we compare their ability to date ex post the occurrence of turning points, evaluate the stability over time of the signal emitted by the models and assess their ability to detect in real-time recession signals. We show that the competitive use of these models provides a more robust analysis and detection of turning points. To perform the complete analysis, we have built a historical vintage database for the euro area going back to 1970 for two monthly macroeconomic variables of major importance for short-term economic outlook, namely the industrial production index and the unemployment rate.</abstract>
            <doi>10.1002/for.2260</doi>
            <url>https://onlinelibrary.wiley.com/doi/pdf/10.1002/for.2260</url>
        </article>
    </entry>
    <entry id="LMMR10">
        <article>
            <author>Lemoine, M. and Mazzi, G. L. and Monperrus-Veroni, P. and Reynes, F.</author>
            <title>A new production function estimate of the {E}uro area output gap</title>
            <journal>#J_JF#</journal>
            <year>2010</year>
            <volume>29</volume>
            <pages>29-53</pages>
            <abstract>We develop a new version of the production function (PF) approach for estimating the output gap of the euro area. Assuming a CES (constant elasticity of substitution) technology, our model does not call for any (often imprecise) measure of the capital stock and improves the estimation of the trend total factor productivity using a multivariate unobserved components model. With real-time data, we assess this approach by comparing it with the Hodrick- Prescott (HP) filter and with a Cobb-Douglas PF approach with common cycle and implemented with a multivariate unobserved components model. Our new PF estimate appears highly concordant with the reference chronology of turning points and has better real-time properties than the univariate HP filter for sufficiently long time horizons. Its inflation forecasting power appears, like the other multivariate approach, less favourable than the statistical univariate method.
</abstract>
            <doi>10.1002/for.1157</doi>
            <url>https://onlinelibrary.wiley.com/doi/epdf/10.1002/for.1157</url>
        </article>
    </entry>
    <entry id="Planas98">
        <article>
            <author>Planas, C.</author>
            <title>Linear signal extraction with intervention techniques in non-linear time series</title>
            <journal>#J_JF#</journal>
            <year>1998</year>
            <volume>17</volume>
            <number>7</number>
            <pages>515-526</pages>
            <abstract>Seasonal adjustment is performed in some data-producing agencies according to the ARIMA-model-based signal extraction theory. A stochastic linear process parametrized in terms of an ARIMA model is first fitted to the series, and from this model the models for the trend, cycle, seasonal, and irregular component can be derived. A spectrum is associated to every component model and is used to compute the optimal Wiener-Kolmogorov filter. Since the modelling is linear, prior linearization of the series with intervention techniques is performed. This paper discusses the performance of linear signal extraction with intervention techniques in non-linear processes. In particular, the following issues are discussed: (1) the ability of intervention techniques to linearize time series which present non-linearities; (2) the stability of the linear projection giving the components estimators under non-linear misspecifications; (3) the capacity of the WK filter to preserve the linearity in some components and the non-linearities in others.</abstract>
            <doi>10.1002/(SICI)1099-131X(199812)17:7&lt;515::AID-FOR678&gt;3.0.CO;2-V</doi>
            <url>https://onlinelibrary.wiley.com/doi/epdf/10.1002/%28SICI%291099-131X%28199812%2917%3A7%3C515%3A%3AAID-FOR678%3E3.0.CO%3B2-V</url>
        </article>
    </entry>
    <entry id="MS00">
        <inproceedings>
            <author>Mercy, J. L. and Sonnberger, H.</author>
            <title>Funding research in data warehousing and knowledge discovery {EPROS}: {T}he {E}uropean plan for research in {O}fficial {S}tatistics</title>
            <booktitle>#C_ICDWKD#</booktitle>
            <year>2000</year>
            <editor>Kambayashi, Y. and Mohania, M. and Tjoa, A. M.</editor>
            <volume>1874</volume>
            <series>#S_LNCS#</series>
            <pages>134-145</pages>
            <publisher>#P_S#</publisher>
            <abstract>This paper discusses: (1) the challenges that the European Statistical System (ESS) faces as the result of the recent appearance of phenomena such as the information society and the new economy, and (2) the extent to which new technological developments in data warehousing, knowledge discovery and extensive use of the internet can contribute to successfully meeting these challenges. Two specific issues are considered: the network nature of the ESS, and the new ways of producing statistics that reinforce the needs for research applied to statistics in domains such as data integration, distributed databases, EDI, automated data capture, analytical tools and dissemination. A historical overview is given of research activities financed by the European Commission as well as their relevance for DaWaK2000. A primary goal of this paper is to provide information about relevant research within the European Statistical System, and to invite the scientific community to participate actively in upcoming calls for proposals and calls for tender financed under the IST programme to solve the urgent needs for timely and high-quality statistics.</abstract>
            <doi>10.1007/3-540-44466-1_14</doi>
            <url>https://link.springer.com/chapter/10.1007%2F3-540-44466-1_14</url>
        </inproceedings>
    </entry>
    <entry id="Radermacher15">
        <article>
            <author>Radermacher, W. J.</author>
            <title>Recent and future developments related to "{GDP} and {B}eyond"</title>
            <journal>#J_RIW#</journal>
            <year>2015</year>
            <volume>61</volume>
            <number>1</number>
            <pages>18-24</pages>
            <abstract>Progress of societies? Well-being of citizens? Trans-generational impact of policies? To answer such fundamental questions and much more, the European Commission published, in August 2009, its Communication on "GDP and Beyond: Measuring Progress in a Changing World." Through a co-operative project, co-chaired by Eurostat and INSEE (France), the ESS acted decisively and established an action plan to be carried out by 2020 in the context of the European Statistical Programme. This plan which also builds on Eurostat's work on Sustainable Development Indicators. For most of these actions, work has either been accomplished or is in good progress. Further challenges lie ahead, including reconciling macro- and micro-data sources on household economic resources and completing the indicators set on Quality-of-Life. The work will also contribute to the global efforts on the Sustainable Development Goals/post-2015 development agenda.</abstract>
            <doi>10.1111/roiw.12135</doi>
            <url>https://onlinelibrary.wiley.com/doi/full/10.1111/roiw.12135</url>
        </article>
    </entry>
    <entry id="ABBFGHJJMMNPRSSSS17">
        <article>
            <author>Aaberge, R. and Bourguignon, F. and Brandolini, A. and Ferreira, F. H. G. and Gornick, J. C. and Hills, J. and J\"antti, M. and Jenkins, S. P. and Marlier, E. and Micklewright, J. and Nolan, B. and Piketty, T. and Radermacher, W. J. and Smeeding, T. M. and Stern, N. H. and Stiglitz, J. and Sutherland, H.</author>
            <title>Tony {A}tkinson and his legacy</title>
            <journal>#J_RIW#</journal>
            <year>2017</year>
            <volume>63</volume>
            <number>3</number>
            <pages>411-444</pages>
            <abstract>Tony Atkinson is universally celebrated for his outstanding contributions to the measurement and analysis of inequality, but he never saw the study of inequality as a separate branch of economics. He was an economist in the classical sense, rejecting any sub‐field labelling of his interests and expertise, and he made contributions right across economics. His death on 1 January 2017 deprived the world of both an intellectual giant and a deeply committed public servant in the broadest sense of the term. This collective tribute highlights the range, depth and importance of Tony's enormous legacy, the product of almost fifty years’ work.</abstract>
            <doi>10.1111/roiw.12335</doi>
            <url>https://onlinelibrary.wiley.com/doi/epdf/10.1111/roiw.12335</url>
        </article>
    </entry>
    <entry id="Kunzler02">
        <article>
            <author>Kunzler, U.</author>
            <title>Electronic data reporting ({EDR}), metadata, standards and the {E}uropean {S}tatistical {S}ystem ({ESS})</title>
            <journal>#J_SJUNECE#</journal>
            <year>2002</year>
            <volume>19</volume>
            <number>3</number>
            <pages>119-130</pages>
            <abstract>We are living in a fast changing world, especially in the ICT (Information and Communication Technologies) sector. In this difficult environment people like to use buzzwords and acronyms - in the title of this paper you find some of them used a lot in the statistical context. It is no problem to add more: CASI, CSAQ, EDI, XML, XBRL - all of them and many more will appear in this article (and in the glossary). It is not always easy for statisticians and ICT specialists to understand each other. However, ICT is needed to automate statistical data reporting in order to save resources and improve processes -- so both communities are condemned to co-operate. In this scenario, a third area with yet another jargon is playing an important role, namely e-business: more and more, statistical EDR is using e-business tools and methods, like for example EDIFACT or ebXML. This paper tries to shed some light on the ICT and e-business aspects of statistical data reporting. The questions addressed in this paper include: What is EDR? What is metadata for EDR? Which metadata standards for EDR are available or coming up? And how is the ESS concerned or involved? The current situation of EDI standardisation is examined in more detail: the transition from EDIFACT to XML and the adoption of ebXML for the ESS. </abstract>
            <url>https://content.iospress.com/articles/statistical-journal-of-the-united-nations-economic-commission-for-europe/sju00523</url>
        </article>
    </entry>
    <entry id="AA96">
        <article>
            <author>Albert, J. and Amor, P.</author>
            <title>Multi-country pilot projects: {A} quantum leap in {E}urostat's statistical assistance to {C}entral and {E}astern {E}urope</title>
            <journal>#J_SJUNECE#</journal>
            <year>1996</year>
            <volume>13</volume>
            <number>1</number>
            <pages>31-40</pages>
            <abstract>The article discusses the new project orientation of the statistical cooperation provided by Eurostat to countries in Central and Eastern Europe. In particular, the criteria used for selecting projects, as well as some of the pilot projects themselves, are described.</abstract>
            <doi>10.3233/SJU-1996-13105</doi>
            <url>https://content.iospress.com/articles/statistical-journal-of-the-united-nations-economic-commission-for-europe/sju13-1-05</url>
        </article>
    </entry>
    <entry id="MM02">
        <article>
            <author>Mikkelsen, L. and Montgomery, R.</author>
            <title>Introduction</title>
            <journal>#J_SJUNECE#</journal>
            <year>2002</year>
            <volume>19</volume>
            <pages>1-3</pages>
            <url>https://content.iospress.com/download/statistical-journal-of-the-united-nations-economic-commission-for-europe/sju00519?id=statistical-journal-of-the-united-nations-economic-commission-for-europe%2Fsju00519</url>
        </article>
    </entry>
    <entry id="Smedt13">
        <article>
            <author>de Smedt, M.</author>
            <title>Measuring subjective issues of well-being and quality of life in the {E}uropean {S}tatistical {S}ystem</title>
            <journal>#J_SIR#</journal>
            <year>2013</year>
            <volume>114</volume>
            <number>1</number>
            <pages>153-167</pages>
            <abstract>Over the last decades, the European Statistical System has developed many European statistics and indicators to measure social progress and sustainable development. Initially only in a few cases the measuring instruments contained questions on subjective issues. With the adoption of its Communication on "gross domestic product and beyond" the Commission has given an impetus to the development of subjective social indicators. This has led to the establishment of a first set of indicators on quality of life and well-being and to a new instrument (the 2013 EU-SILC ad-hoc module for measuring subjective well-being). This new step in European statistics creates an important potential for researchers to engage in in-depth analysis and for national and European Union policy makers to use the resulting indicators-and in casu subjective well-being indicators-for developing and monitoring policy strategies and programmes.</abstract>
            <doi>10.1007/s11205-013-0389-5</doi>
            <url>https://link.springer.com/article/10.1007/s11205-013-0389-5</url>
        </article>
    </entry>
    <entry id="MS17">
        <article>
            <author>Bouwmeester, M. C. and Scholtens, B.</author>
            <title>Cross-border investment expenditure spillovers in {E}uropean gas infrastructure</title>
            <journal>#J_EP#</journal>
            <year>2017</year>
            <volume>106</volume>
            <pages>288-297</pages>
            <abstract>We investigate the implications of an integrated vis-à-vis a national perspective regarding investment in natural gas infrastructure. In particular, we analyze cross-border spillovers related to the investment expenditure of five Western European countries. We develop a practical approach to estimate such cross-border investment expenditure spillovers using a multi-regional input-output model. We find that international spillovers are generally larger for employment compensation compared to capital compensation and that the spillovers are unevenly distributed among the countries and the types of labor. Both high-skilled and medium-skilled labor is impacted most in the country where the investments take place, whereas low-skilled labor is mostly generated outside the EU. We argue that an integrated European gas infrastructure investment policy is to be recommended.
</abstract>
            <doi>10.1016/j.enpol.2017.05.010</doi>
            <url>https://reader.elsevier.com/reader/sd/pii/S0301421517302951</url>
        </article>
    </entry>
    <entry id="BO17">
        <article>
            <author>Bouwmeester, M. C. and Oosterhaven, J.</author>
            <title>Economic impacts of natural gas flow disruptions between {R}ussia and the {EU}</title>
            <journal>#J_EP#</journal>
            <year>2017</year>
            <volume>106</volume>
            <pages>288-297</pages>
            <abstract>In this paper we use a non-linear programming approach to predict the wider interregional and interindustry impacts of natural gas flow disruptions. In the short run, economic actors attempt to continue their business-as-usual and follow established trade patters as closely as possible. In the model this is modelled by minimizing the information gain between the original pattern of economic transactions and the situation in which natural gas flows are disrupted. We analyze four scenarios that simulate Russian export stops of natural gas by means of a model calibrated on an international input-output table with six sectors and six regions. The simulations show that at the lower levels of aggregation considerable effects are found. At the aggregate level of the whole economy, however, the impacts of the four scenarios are negligible for Europe and only a little less so for Russia itself. Interestingly, the effects on the size of the economy, as measured by its GDP, are predominantly positive for the various European regions, but negative for Russia. The effects on the welfare of the populations involved, however, as measured by the size of domestic final demand, have an opposite sign; with predominantly negligible but negative effects for European regions, and very small positive effects for the Russian population.</abstract>
            <doi>10.1016/j.enpol.2017.03.030</doi>
            <url>https://reader.elsevier.com/reader/sd/pii/S030142151730174X</url>
        </article>
    </entry>
    <entry id="MMM14">
        <article>
            <author>Mazzi, G. L. and Mitchell, J. and Montana, G.</author>
            <title>Density nowcasts and model combination: {N}owcasting euro-area {GDP} growth over the 2008-09 recession</title>
            <journal>#J_OBES#</journal>
            <year>2014</year>
            <volume>76</volume>
            <number>2</number>
            <pages>233-256</pages>
            <abstract>Combined density nowcasts for quarterly Euro‐area GDP growth are produced based on the real‐time performance of component models. Components are distinguished by their use of ‘hard’ and ‘soft’, aggregate and disaggregate, indicators. We consider the accuracy of the density nowcasts as within‐quarter indicator data accumulate. We find that the relative utility of ‘soft’ indicators surged during the recession. But as this instability was hard to detect in real‐time it helps, when producing density nowcasts unknowing any within‐quarter ‘hard’ data, to weight the different indicators equally. On receipt of ‘hard’ data for the second month in the quarter better calibrated densities are obtained by giving a higher weight in the combination to ‘hard’ indicators.</abstract>
            <doi>10.1111/obes.12015</doi>
            <url>https://onlinelibrary.wiley.com/doi/epdf/10.1111/obes.12015</url>
        </article>
    </entry>
    <entry id="GPFMM15">
        <article>
            <author>Grassi, S. and Proietti, T. and Frale, C. and Marcellino, M. and Mazzi, G. L.</author>
            <title>Euro{MI}nd-{C}: {A} disaggregate monthly indicator of economic activity for the {E}uro area and member countries</title>
            <journal>#J_IJF#</journal>
            <year>2015</year>
            <volume>31</volume>
            <number>3</number>
            <pages>712-738</pages>
            <abstract>This paper deals with the estimation of monthly indicators of economic activity for the Euro area and its largest member countries that possess the following attributes: relevance, representativeness and timeliness. Relevance is determined by comparing our monthly indicators to the gross domestic product at chained volumes, as the most important measure of the level of economic activity. Representativeness is achieved by considering a very large number of (timely) time series of monthly indicators relating to the level of economic activity, providing a more or less complete coverage. The indicators are modelled using a large-scale parametric factor model. We discuss its specification and provide details of the statistical treatment. Computational efficiency is crucial for the estimation of large-scale parametric factor models of the dimension used in our application (considering about 170 series). To achieve it, we apply state-of-the-art state space methods that can handle temporal aggregation, and any pattern of missing values.</abstract>
            <doi>10.1016/j.ijforecast.2014.08.015</doi>
            <url>https://www.sciencedirect.com/science/article/abs/pii/S0169207014001484?via%3Dihub</url>
        </article>
    </entry>
    <entry id="TDWMB13">
        <article>
            <author>Tukker, A. and De Koning, A. and Wood, R. and Moll, S. and Bouwmeester, M. C.</author>
            <title>Price corrected domestic technology assumption \textendash{} {A} method to assess pollution embodied in trade using primary {O}fficial {S}tatistics only. {W}ith a case on {CO2} emissions embodied in imports to {E}urope</title>
            <journal>#J_EST#</journal>
            <year>2013</year>
            <volume>47</volume>
            <number>4</number>
            <pages>1775-1783</pages>
            <note>\href{https://pubs.acs.org/doi/suppl/10.1021/es303217f/suppl_file/es303217f_si_002.pdf}{Additional material}</note>
            <abstract>Environmentally extended input output (EE IO) analysis is increasingly used to assess the carbon footprint of final consumption. Official EE IO data are, however, at best available for single countries or regions such as the EU27. This causes problems in assessing pollution embodied in imported products. The popular “domestic technology assumption (DTA)” leads to errors. Improved approaches based on Life Cycle Inventory data, Multiregional EE IO tables, etc. rely on unofficial research data and modeling, making them difficult to implement by statistical offices. The DTA can lead to errors for three main reasons: exporting countries can have higher impact intensities; may use more intermediate inputs for the same output; or may sell the imported products for lower/other prices than those produced domestically. The last factor is relevant for sustainable consumption policies of importing countries, whereas the first factors are mainly a matter of making production in exporting countries more eco-efficient. We elaborated a simple correction for price differences in imports and domestic production using monetary and physical data from official import and export statistics. A case study for the EU27 shows that this “price-adjusted DTA” gives a partial but meaningful adjustment of pollution embodied in trade compared to multiregional EE IO studies.</abstract>
            <doi>10.1021/es303217f</doi>
            <url>https://pubs.acs.org/doi/full/10.1021/es303217f</url>
        </article>
    </entry>
</file>
